{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import joblib\n",
    "import gc  # For garbage collection\n",
    "\n",
    "# Import from our refactored modules\n",
    "from common import (\n",
    "    # Logger\n",
    "    logger, setup_logger,\n",
    "    \n",
    "    # Data loading\n",
    "    load_eeg_data,\n",
    "\n",
    "    # Data quality analysis\n",
    "    analyze_data_quality,\n",
    "    \n",
    "    # Preprocessing\n",
    "    preprocess_eeg_data, engineer_eeg_features,\n",
    "    \n",
    "    # Disk-based bundle functions\n",
    "    create_coherent_time_series_bundles_disk, normalize_bundles_disk,\n",
    "    \n",
    "    # Models\n",
    "    UnsupervisedModelTrainer,\n",
    "    \n",
    "    # Visualization\n",
    "    visualize_eeg_data\n",
    ")\n",
    "\n",
    "def print_section_header(title):\n",
    "    \"\"\"Print a section header to make output easier to read\"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(f\" {title}\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "def setup_directories(base_dir):\n",
    "    \"\"\"Create output directories if they don't exist\"\"\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    \n",
    "    # Create subdirectories\n",
    "    models_dir = os.path.join(base_dir, \"models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    plots_dir = os.path.join(base_dir, \"plots\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    bundle_dir = os.path.join(base_dir, \"bundles\")\n",
    "    os.makedirs(bundle_dir, exist_ok=True)\n",
    "    \n",
    "    return {\n",
    "        \"base\": base_dir,\n",
    "        \"models\": models_dir,\n",
    "        \"plots\": plots_dir,\n",
    "        \"bundles\": bundle_dir\n",
    "    }\n",
    "\n",
    "def save_plot(fig, filename, output_dir):\n",
    "    \"\"\"Save matplotlib figure to file\"\"\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    fig.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    logger.info(f\"Saved plot: {filepath}\")\n",
    "\n",
    "def load_bundle_info(bundle_dir):\n",
    "    \"\"\"\n",
    "    Load bundle information from a directory\n",
    "    \n",
    "    Parameters:\n",
    "        bundle_dir (str): Path to the directory containing bundle information\n",
    "        \n",
    "    Returns:\n",
    "        dict: Bundle information dictionary\n",
    "    \"\"\"\n",
    "    # Check for bundle info file\n",
    "    info_path = os.path.join(bundle_dir, \"bundle_info.joblib\")\n",
    "    \n",
    "    if not os.path.exists(info_path):\n",
    "        raise FileNotFoundError(f\"Bundle info file not found in {bundle_dir}\")\n",
    "    \n",
    "    # Load bundle info\n",
    "    bundle_info = joblib.load(info_path)\n",
    "    \n",
    "    # Validate the bundle info\n",
    "    required_keys = ['total_bundles', 'bundle_size', 'feature_dim', 'output_dir']\n",
    "    for key in required_keys:\n",
    "        if key not in bundle_info:\n",
    "            raise ValueError(f\"Bundle info is missing required key: {key}\")\n",
    "    \n",
    "    # Make sure paths are correct if the bundles were moved\n",
    "    if os.path.abspath(bundle_info['output_dir']) != os.path.abspath(bundle_dir):\n",
    "        logger.warning(f\"Bundle directory has changed from {bundle_info['output_dir']} to {bundle_dir}\")\n",
    "        bundle_info['output_dir'] = os.path.abspath(bundle_dir)\n",
    "    \n",
    "    return bundle_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,467 - eeg_classification - INFO - Starting EEG Processing Pipeline\n",
      "2025-03-14 09:27:45,467 - eeg_classification - INFO - Starting EEG Processing Pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,467 - eeg_classification - INFO - Starting EEG Processing Pipeline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,471 - eeg_classification - INFO - Data directory: ../data\n",
      "2025-03-14 09:27:45,471 - eeg_classification - INFO - Data directory: ../data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,471 - eeg_classification - INFO - Data directory: ../data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,473 - eeg_classification - INFO - Output directory: ./eeg_bundles\n",
      "2025-03-14 09:27:45,473 - eeg_classification - INFO - Output directory: ./eeg_bundles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,473 - eeg_classification - INFO - Output directory: ./eeg_bundles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,475 - eeg_classification - INFO - Log file: ./eeg_bundles\\logs\\pipeline_20250314_092745.log\n",
      "2025-03-14 09:27:45,475 - eeg_classification - INFO - Log file: ./eeg_bundles\\logs\\pipeline_20250314_092745.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,475 - eeg_classification - INFO - Log file: ./eeg_bundles\\logs\\pipeline_20250314_092745.log\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./eeg_bundles\"\n",
    "log_level = \"INFO\"\n",
    "data_dir = \"../data\"\n",
    "load_existing = True\n",
    "n_clusters = 2\n",
    "bundle_size = 30\n",
    "step_size = 30\n",
    "\n",
    "# Configure logging\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = os.path.join(output_dir, \"logs\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file = os.path.join(log_dir, f\"pipeline_{timestamp}.log\")\n",
    "\n",
    "# Convert string log level to actual level\n",
    "numeric_level = getattr(logging, log_level.upper(), None)\n",
    "setup_logger(name=\"eeg_classification\", level=numeric_level, log_file=log_file)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "logger.info(\"Starting EEG Processing Pipeline\")\n",
    "logger.info(f\"Data directory: {data_dir}\")\n",
    "logger.info(f\"Output directory: {output_dir}\")\n",
    "logger.info(f\"Log file: {log_file}\")\n",
    "\n",
    "# Setup directories\n",
    "dirs = setup_directories(output_dir)\n",
    "\n",
    "# Set bundle directory\n",
    "bundle_dir = dirs[\"bundles\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,506 - eeg_classification - INFO - Checking for existing bundles...\n",
      "2025-03-14 09:27:45,506 - eeg_classification - INFO - Checking for existing bundles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,506 - eeg_classification - INFO - Checking for existing bundles...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,509 - eeg_classification - WARNING - Could not load existing bundles: Bundle info file not found in ./eeg_bundles\\bundles\n",
      "2025-03-14 09:27:45,509 - eeg_classification - WARNING - Could not load existing bundles: Bundle info file not found in ./eeg_bundles\\bundles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,509 - eeg_classification - WARNING - Could not load existing bundles: Bundle info file not found in ./eeg_bundles\\bundles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,514 - eeg_classification - INFO - \n",
      "================================================================================\n",
      "2025-03-14 09:27:45,514 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,514 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,516 - eeg_classification - INFO -  Step 1: Loading EEG data\n",
      "2025-03-14 09:27:45,516 - eeg_classification - INFO -  Step 1: Loading EEG data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,516 - eeg_classification - INFO -  Step 1: Loading EEG data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,518 - eeg_classification - INFO - ================================================================================\n",
      "2025-03-14 09:27:45,518 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,518 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,520 - eeg_classification - INFO - Loading data from ../data\n",
      "2025-03-14 09:27:45,520 - eeg_classification - INFO - Loading data from ../data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:27:45,520 - eeg_classification - INFO - Loading data from ../data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,886 - eeg_classification - INFO - Loaded 30 files with 6947837 total rows\n",
      "2025-03-14 09:28:24,886 - eeg_classification - INFO - Loaded 30 files with 6947837 total rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,886 - eeg_classification - INFO - Loaded 30 files with 6947837 total rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,889 - eeg_classification - INFO - Loaded 30 files with 6947837 total rows\n",
      "2025-03-14 09:28:24,889 - eeg_classification - INFO - Loaded 30 files with 6947837 total rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,889 - eeg_classification - INFO - Loaded 30 files with 6947837 total rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,891 - eeg_classification - INFO - Sample file file_1 shape: (108335, 42)\n",
      "2025-03-14 09:28:24,891 - eeg_classification - INFO - Sample file file_1 shape: (108335, 42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,891 - eeg_classification - INFO - Sample file file_1 shape: (108335, 42)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,901 - eeg_classification - WARNING - Too many columns (39). Showing only the first 5.\n",
      "2025-03-14 09:28:24,901 - eeg_classification - WARNING - Too many columns (39). Showing only the first 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,901 - eeg_classification - WARNING - Too many columns (39). Showing only the first 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,963 - eeg_classification - ERROR - Error loading data: time data \"2024-06-02 09:47:18\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 156. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "2025-03-14 09:28:24,963 - eeg_classification - ERROR - Error loading data: time data \"2024-06-02 09:47:18\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 156. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,963 - eeg_classification - ERROR - Error loading data: time data \"2024-06-02 09:47:18\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 156. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,966 - eeg_classification - ERROR - Stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Huai\\AppData\\Local\\Temp\\ipykernel_32816\\609321440.py\", line 35, in <module>\n",
      "    fig = visualize_eeg_data(sample_df, max_cols=5)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\visualization.py\", line 51, in visualize_eeg_data\n",
      "    x = pd.to_datetime(df['TimeStamp'])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 1063, in to_datetime\n",
      "    cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 247, in _maybe_cache\n",
      "    cache_dates = convert_listlike(unique_dates, format)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 433, in _convert_listlike_datetimes\n",
      "    return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 467, in _array_strptime_with_fallback\n",
      "    result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"strptime.pyx\", line 501, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 451, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 583, in pandas._libs.tslibs.strptime._parse_with_format\n",
      "ValueError: time data \"2024-06-02 09:47:18\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 156. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "2025-03-14 09:28:24,966 - eeg_classification - ERROR - Stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Huai\\AppData\\Local\\Temp\\ipykernel_32816\\609321440.py\", line 35, in <module>\n",
      "    fig = visualize_eeg_data(sample_df, max_cols=5)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\visualization.py\", line 51, in visualize_eeg_data\n",
      "    x = pd.to_datetime(df['TimeStamp'])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 1063, in to_datetime\n",
      "    cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 247, in _maybe_cache\n",
      "    cache_dates = convert_listlike(unique_dates, format)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 433, in _convert_listlike_datetimes\n",
      "    return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 467, in _array_strptime_with_fallback\n",
      "    result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"strptime.pyx\", line 501, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 451, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 583, in pandas._libs.tslibs.strptime._parse_with_format\n",
      "ValueError: time data \"2024-06-02 09:47:18\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 156. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,966 - eeg_classification - ERROR - Stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Huai\\AppData\\Local\\Temp\\ipykernel_32816\\609321440.py\", line 35, in <module>\n",
      "    fig = visualize_eeg_data(sample_df, max_cols=5)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\visualization.py\", line 51, in visualize_eeg_data\n",
      "    x = pd.to_datetime(df['TimeStamp'])\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 1063, in to_datetime\n",
      "    cache_array = _maybe_cache(arg, format, cache, convert_listlike)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 247, in _maybe_cache\n",
      "    cache_dates = convert_listlike(unique_dates, format)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 433, in _convert_listlike_datetimes\n",
      "    return _array_strptime_with_fallback(arg, name, utc, format, exact, errors)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py\", line 467, in _array_strptime_with_fallback\n",
      "    result, tz_out = array_strptime(arg, fmt, exact=exact, errors=errors, utc=utc)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"strptime.pyx\", line 501, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 451, in pandas._libs.tslibs.strptime.array_strptime\n",
      "  File \"strptime.pyx\", line 583, in pandas._libs.tslibs.strptime._parse_with_format\n",
      "ValueError: time data \"2024-06-02 09:47:18\" doesn't match format \"%Y-%m-%d %H:%M:%S.%f\", at position 156. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,971 - eeg_classification - INFO - Step 1 completed in 39.45 seconds\n",
      "2025-03-14 09:28:24,971 - eeg_classification - INFO - Step 1 completed in 39.45 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,971 - eeg_classification - INFO - Step 1 completed in 39.45 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,973 - eeg_classification - INFO - \n",
      "================================================================================\n",
      "2025-03-14 09:28:24,973 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,973 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,976 - eeg_classification - INFO -  Step 2: Processing data and engineering features\n",
      "2025-03-14 09:28:24,976 - eeg_classification - INFO -  Step 2: Processing data and engineering features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,976 - eeg_classification - INFO -  Step 2: Processing data and engineering features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,977 - eeg_classification - INFO - ================================================================================\n",
      "2025-03-14 09:28:24,977 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,977 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,979 - eeg_classification - INFO - Analyzing data quality for sample file file_1\n",
      "2025-03-14 09:28:24,979 - eeg_classification - INFO - Analyzing data quality for sample file file_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,979 - eeg_classification - INFO - Analyzing data quality for sample file file_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,998 - eeg_classification - INFO - Data shape: 108335 rows × 42 columns\n",
      "2025-03-14 09:28:24,998 - eeg_classification - INFO - Data shape: 108335 rows × 42 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:24,998 - eeg_classification - INFO - Data shape: 108335 rows × 42 columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,000 - eeg_classification - INFO - Total missing values: 116505 (2.56%)\n",
      "2025-03-14 09:28:25,000 - eeg_classification - INFO - Total missing values: 116505 (2.56%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,000 - eeg_classification - INFO - Total missing values: 116505 (2.56%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,019 - eeg_classification - WARNING - Found 1 columns with >50.0% NaN values:\n",
      "2025-03-14 09:28:25,019 - eeg_classification - WARNING - Found 1 columns with >50.0% NaN values:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,019 - eeg_classification - WARNING - Found 1 columns with >50.0% NaN values:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,022 - eeg_classification - WARNING -   - Elements: 99.8% NaNs (108120 values)\n",
      "2025-03-14 09:28:25,022 - eeg_classification - WARNING -   - Elements: 99.8% NaNs (108120 values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,022 - eeg_classification - WARNING -   - Elements: 99.8% NaNs (108120 values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,025 - eeg_classification - INFO - Found 2 columns with no NaN values\n",
      "2025-03-14 09:28:25,025 - eeg_classification - INFO - Found 2 columns with no NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,025 - eeg_classification - INFO - Found 2 columns with no NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,177 - eeg_classification - INFO - Recommendations based on data quality analysis:\n",
      "2025-03-14 09:28:25,177 - eeg_classification - INFO - Recommendations based on data quality analysis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,177 - eeg_classification - INFO - Recommendations based on data quality analysis:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,179 - eeg_classification - INFO - 1. Consider dropping columns with high NaN percentages: Elements\n",
      "2025-03-14 09:28:25,179 - eeg_classification - INFO - 1. Consider dropping columns with high NaN percentages: Elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,179 - eeg_classification - INFO - 1. Consider dropping columns with high NaN percentages: Elements\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,846 - eeg_classification - INFO - Saved plot: ./eeg_bundles\\plots\\sample_data_quality.png\n",
      "2025-03-14 09:28:25,846 - eeg_classification - INFO - Saved plot: ./eeg_bundles\\plots\\sample_data_quality.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,846 - eeg_classification - INFO - Saved plot: ./eeg_bundles\\plots\\sample_data_quality.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,849 - eeg_classification - INFO - Saved list of ['Elements'] high-NaN columns for reference\n",
      "2025-03-14 09:28:25,849 - eeg_classification - INFO - Saved list of ['Elements'] high-NaN columns for reference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,849 - eeg_classification - INFO - Saved list of ['Elements'] high-NaN columns for reference\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,851 - eeg_classification - INFO - Processing file file_1 with 108335 rows\n",
      "2025-03-14 09:28:25,851 - eeg_classification - INFO - Processing file file_1 with 108335 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,851 - eeg_classification - INFO - Processing file file_1 with 108335 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,874 - eeg_classification - WARNING - Input data for file file_1 contains 8385 NaN values\n",
      "2025-03-14 09:28:25,874 - eeg_classification - WARNING - Input data for file file_1 contains 8385 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,874 - eeg_classification - WARNING - Input data for file file_1 contains 8385 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,876 - eeg_classification - INFO - Preprocessing data with shape (108335, 41)\n",
      "2025-03-14 09:28:25,876 - eeg_classification - INFO - Preprocessing data with shape (108335, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,876 - eeg_classification - INFO - Preprocessing data with shape (108335, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,943 - eeg_classification - WARNING - Dropping 215 rows with invalid timestamps\n",
      "2025-03-14 09:28:25,943 - eeg_classification - WARNING - Dropping 215 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,943 - eeg_classification - WARNING - Dropping 215 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,958 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 108120\n",
      "2025-03-14 09:28:25,958 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 108120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:25,958 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 108120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:26,019 - eeg_classification - INFO - Data spans 422.21 seconds from 2024-06-02 09:47:17.286000 to 2024-06-02 09:54:19.497000\n",
      "2025-03-14 09:28:26,019 - eeg_classification - INFO - Data spans 422.21 seconds from 2024-06-02 09:47:17.286000 to 2024-06-02 09:54:19.497000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,019 - eeg_classification - INFO - Data spans 422.21 seconds from 2024-06-02 09:47:17.286000 to 2024-06-02 09:54:19.497000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,125 - eeg_classification - INFO - Sampling complete: 108120 -> 4250 data points (3.9%)\n",
      "2025-03-14 09:28:26,125 - eeg_classification - INFO - Sampling complete: 108120 -> 4250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,125 - eeg_classification - INFO - Sampling complete: 108120 -> 4250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,134 - eeg_classification - INFO - Preprocessing complete. Output shape: (4250, 41)\n",
      "2025-03-14 09:28:26,134 - eeg_classification - INFO - Preprocessing complete. Output shape: (4250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,134 - eeg_classification - INFO - Preprocessing complete. Output shape: (4250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,136 - eeg_classification - INFO - Cleaned data shape: (4250, 41)\n",
      "2025-03-14 09:28:26,136 - eeg_classification - INFO - Cleaned data shape: (4250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,136 - eeg_classification - INFO - Cleaned data shape: (4250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,138 - eeg_classification - INFO - Engineering features from data with shape (4250, 41)\n",
      "2025-03-14 09:28:26,138 - eeg_classification - INFO - Engineering features from data with shape (4250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,138 - eeg_classification - INFO - Engineering features from data with shape (4250, 41)\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,336 - eeg_classification - INFO - Feature engineering complete. Output shape: (4250, 140)\n",
      "2025-03-14 09:28:26,336 - eeg_classification - INFO - Feature engineering complete. Output shape: (4250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:26,336 - eeg_classification - INFO - Feature engineering complete. Output shape: (4250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,338 - eeg_classification - INFO - Features shape: (4250, 140)\n",
      "2025-03-14 09:28:26,338 - eeg_classification - INFO - Features shape: (4250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,338 - eeg_classification - INFO - Features shape: (4250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,345 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:26,345 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,345 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,348 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:26,348 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,348 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,355 - eeg_classification - WARNING - Too many columns (138). Showing only the first 5.\n",
      "2025-03-14 09:28:26,355 - eeg_classification - WARNING - Too many columns (138). Showing only the first 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:26,355 - eeg_classification - WARNING - Too many columns (138). Showing only the first 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,367 - eeg_classification - INFO - Saved plot: ./eeg_bundles\\plots\\processed_eeg_data.png\n",
      "2025-03-14 09:28:27,367 - eeg_classification - INFO - Saved plot: ./eeg_bundles\\plots\\processed_eeg_data.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,367 - eeg_classification - INFO - Saved plot: ./eeg_bundles\\plots\\processed_eeg_data.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,517 - eeg_classification - INFO - Processing file file_2 with 75708 rows\n",
      "2025-03-14 09:28:27,517 - eeg_classification - INFO - Processing file file_2 with 75708 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,517 - eeg_classification - INFO - Processing file file_2 with 75708 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,536 - eeg_classification - WARNING - Input data for file file_2 contains 3048 NaN values\n",
      "2025-03-14 09:28:27,536 - eeg_classification - WARNING - Input data for file file_2 contains 3048 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,536 - eeg_classification - WARNING - Input data for file file_2 contains 3048 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,538 - eeg_classification - INFO - Preprocessing data with shape (75708, 41)\n",
      "2025-03-14 09:28:27,538 - eeg_classification - INFO - Preprocessing data with shape (75708, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,538 - eeg_classification - INFO - Preprocessing data with shape (75708, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,586 - eeg_classification - WARNING - Dropping 48 rows with invalid timestamps\n",
      "2025-03-14 09:28:27,586 - eeg_classification - WARNING - Dropping 48 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,586 - eeg_classification - WARNING - Dropping 48 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,599 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 75660\n",
      "2025-03-14 09:28:27,599 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 75660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,599 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 75660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:27,648 - eeg_classification - INFO - Data spans 295.30 seconds from 2024-06-03 05:38:00.925000 to 2024-06-03 05:42:56.225000\n",
      "2025-03-14 09:28:27,648 - eeg_classification - INFO - Data spans 295.30 seconds from 2024-06-03 05:38:00.925000 to 2024-06-03 05:42:56.225000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,648 - eeg_classification - INFO - Data spans 295.30 seconds from 2024-06-03 05:38:00.925000 to 2024-06-03 05:42:56.225000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,710 - eeg_classification - INFO - Sampling complete: 75204 -> 3000 data points (4.0%)\n",
      "2025-03-14 09:28:27,710 - eeg_classification - INFO - Sampling complete: 75204 -> 3000 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,710 - eeg_classification - INFO - Sampling complete: 75204 -> 3000 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,715 - eeg_classification - INFO - Preprocessing complete. Output shape: (3000, 41)\n",
      "2025-03-14 09:28:27,715 - eeg_classification - INFO - Preprocessing complete. Output shape: (3000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,715 - eeg_classification - INFO - Preprocessing complete. Output shape: (3000, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,717 - eeg_classification - INFO - Cleaned data shape: (3000, 41)\n",
      "2025-03-14 09:28:27,717 - eeg_classification - INFO - Cleaned data shape: (3000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,717 - eeg_classification - INFO - Cleaned data shape: (3000, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,719 - eeg_classification - INFO - Engineering features from data with shape (3000, 41)\n",
      "2025-03-14 09:28:27,719 - eeg_classification - INFO - Engineering features from data with shape (3000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,719 - eeg_classification - INFO - Engineering features from data with shape (3000, 41)\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,865 - eeg_classification - INFO - Feature engineering complete. Output shape: (3000, 140)\n",
      "2025-03-14 09:28:27,865 - eeg_classification - INFO - Feature engineering complete. Output shape: (3000, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:27,865 - eeg_classification - INFO - Feature engineering complete. Output shape: (3000, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,867 - eeg_classification - INFO - Features shape: (3000, 140)\n",
      "2025-03-14 09:28:27,867 - eeg_classification - INFO - Features shape: (3000, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,867 - eeg_classification - INFO - Features shape: (3000, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,874 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:27,874 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,874 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,877 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:27,877 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:27,877 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,015 - eeg_classification - INFO - Processing file file_3 with 129164 rows\n",
      "2025-03-14 09:28:28,015 - eeg_classification - INFO - Processing file file_3 with 129164 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,015 - eeg_classification - INFO - Processing file file_3 with 129164 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,044 - eeg_classification - WARNING - Input data for file file_3 contains 4992 NaN values\n",
      "2025-03-14 09:28:28,044 - eeg_classification - WARNING - Input data for file file_3 contains 4992 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,044 - eeg_classification - WARNING - Input data for file file_3 contains 4992 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,046 - eeg_classification - INFO - Preprocessing data with shape (129164, 41)\n",
      "2025-03-14 09:28:28,046 - eeg_classification - INFO - Preprocessing data with shape (129164, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,046 - eeg_classification - INFO - Preprocessing data with shape (129164, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,125 - eeg_classification - WARNING - Dropping 128 rows with invalid timestamps\n",
      "2025-03-14 09:28:28,125 - eeg_classification - WARNING - Dropping 128 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,125 - eeg_classification - WARNING - Dropping 128 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,144 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 129036\n",
      "2025-03-14 09:28:28,144 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 129036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,144 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 129036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:28,220 - eeg_classification - INFO - Data spans 503.95 seconds from 2024-06-05 17:23:37.961000 to 2024-06-05 17:32:01.910000\n",
      "2025-03-14 09:28:28,220 - eeg_classification - INFO - Data spans 503.95 seconds from 2024-06-05 17:23:37.961000 to 2024-06-05 17:32:01.910000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,220 - eeg_classification - INFO - Data spans 503.95 seconds from 2024-06-05 17:23:37.961000 to 2024-06-05 17:32:01.910000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,351 - eeg_classification - INFO - Sampling complete: 129036 -> 5050 data points (3.9%)\n",
      "2025-03-14 09:28:28,351 - eeg_classification - INFO - Sampling complete: 129036 -> 5050 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,351 - eeg_classification - INFO - Sampling complete: 129036 -> 5050 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,360 - eeg_classification - INFO - Preprocessing complete. Output shape: (5050, 41)\n",
      "2025-03-14 09:28:28,360 - eeg_classification - INFO - Preprocessing complete. Output shape: (5050, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,360 - eeg_classification - INFO - Preprocessing complete. Output shape: (5050, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,363 - eeg_classification - INFO - Cleaned data shape: (5050, 41)\n",
      "2025-03-14 09:28:28,363 - eeg_classification - INFO - Cleaned data shape: (5050, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,363 - eeg_classification - INFO - Cleaned data shape: (5050, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,366 - eeg_classification - INFO - Engineering features from data with shape (5050, 41)\n",
      "2025-03-14 09:28:28,366 - eeg_classification - INFO - Engineering features from data with shape (5050, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,366 - eeg_classification - INFO - Engineering features from data with shape (5050, 41)\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,591 - eeg_classification - INFO - Feature engineering complete. Output shape: (5050, 140)\n",
      "2025-03-14 09:28:28,591 - eeg_classification - INFO - Feature engineering complete. Output shape: (5050, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:28,591 - eeg_classification - INFO - Feature engineering complete. Output shape: (5050, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,593 - eeg_classification - INFO - Features shape: (5050, 140)\n",
      "2025-03-14 09:28:28,593 - eeg_classification - INFO - Features shape: (5050, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,593 - eeg_classification - INFO - Features shape: (5050, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,601 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:28,601 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,601 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,603 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:28,603 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,603 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,818 - eeg_classification - INFO - Processing file file_4 with 308318 rows\n",
      "2025-03-14 09:28:28,818 - eeg_classification - INFO - Processing file file_4 with 308318 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,818 - eeg_classification - INFO - Processing file file_4 with 308318 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,877 - eeg_classification - WARNING - Input data for file file_4 contains 662202 NaN values\n",
      "2025-03-14 09:28:28,877 - eeg_classification - WARNING - Input data for file file_4 contains 662202 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,877 - eeg_classification - WARNING - Input data for file file_4 contains 662202 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,878 - eeg_classification - INFO - Preprocessing data with shape (308318, 41)\n",
      "2025-03-14 09:28:28,878 - eeg_classification - INFO - Preprocessing data with shape (308318, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:28,878 - eeg_classification - INFO - Preprocessing data with shape (308318, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,099 - eeg_classification - WARNING - Dropping 146 rows with invalid timestamps\n",
      "2025-03-14 09:28:29,099 - eeg_classification - WARNING - Dropping 146 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,099 - eeg_classification - WARNING - Dropping 146 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,137 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 308172\n",
      "2025-03-14 09:28:29,137 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 308172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,137 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 308172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:29,310 - eeg_classification - INFO - Data spans 1247.12 seconds from 2024-06-05 17:33:40.475000 to 2024-06-05 17:54:27.593000\n",
      "2025-03-14 09:28:29,310 - eeg_classification - INFO - Data spans 1247.12 seconds from 2024-06-05 17:33:40.475000 to 2024-06-05 17:54:27.593000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,310 - eeg_classification - INFO - Data spans 1247.12 seconds from 2024-06-05 17:33:40.475000 to 2024-06-05 17:54:27.593000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,585 - eeg_classification - INFO - Sampling complete: 93276 -> 12082 data points (13.0%)\n",
      "2025-03-14 09:28:29,585 - eeg_classification - INFO - Sampling complete: 93276 -> 12082 data points (13.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,585 - eeg_classification - INFO - Sampling complete: 93276 -> 12082 data points (13.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,593 - eeg_classification - INFO - Preprocessing complete. Output shape: (12082, 41)\n",
      "2025-03-14 09:28:29,593 - eeg_classification - INFO - Preprocessing complete. Output shape: (12082, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,593 - eeg_classification - INFO - Preprocessing complete. Output shape: (12082, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,595 - eeg_classification - INFO - Cleaned data shape: (12082, 41)\n",
      "2025-03-14 09:28:29,595 - eeg_classification - INFO - Cleaned data shape: (12082, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,595 - eeg_classification - INFO - Cleaned data shape: (12082, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,597 - eeg_classification - INFO - Engineering features from data with shape (12082, 41)\n",
      "2025-03-14 09:28:29,597 - eeg_classification - INFO - Engineering features from data with shape (12082, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:29,597 - eeg_classification - INFO - Engineering features from data with shape (12082, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,087 - eeg_classification - INFO - Feature engineering complete. Output shape: (12082, 140)\n",
      "2025-03-14 09:28:30,087 - eeg_classification - INFO - Feature engineering complete. Output shape: (12082, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:30,087 - eeg_classification - INFO - Feature engineering complete. Output shape: (12082, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,089 - eeg_classification - INFO - Features shape: (12082, 140)\n",
      "2025-03-14 09:28:30,089 - eeg_classification - INFO - Features shape: (12082, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,089 - eeg_classification - INFO - Features shape: (12082, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,099 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:30,099 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,099 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,102 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:30,102 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,102 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,242 - eeg_classification - INFO - Processing file file_5 with 291703 rows\n",
      "2025-03-14 09:28:30,242 - eeg_classification - INFO - Processing file file_5 with 291703 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,242 - eeg_classification - INFO - Processing file file_5 with 291703 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,296 - eeg_classification - WARNING - Input data for file file_5 contains 4953 NaN values\n",
      "2025-03-14 09:28:30,296 - eeg_classification - WARNING - Input data for file file_5 contains 4953 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,296 - eeg_classification - WARNING - Input data for file file_5 contains 4953 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,298 - eeg_classification - INFO - Preprocessing data with shape (291703, 41)\n",
      "2025-03-14 09:28:30,298 - eeg_classification - INFO - Preprocessing data with shape (291703, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,298 - eeg_classification - INFO - Preprocessing data with shape (291703, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,499 - eeg_classification - WARNING - Dropping 127 rows with invalid timestamps\n",
      "2025-03-14 09:28:30,499 - eeg_classification - WARNING - Dropping 127 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,499 - eeg_classification - WARNING - Dropping 127 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,536 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 291576\n",
      "2025-03-14 09:28:30,536 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 291576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,536 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 291576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:30,692 - eeg_classification - INFO - Data spans 1138.85 seconds from 2024-06-06 12:56:03.180000 to 2024-06-06 13:15:02.029000\n",
      "2025-03-14 09:28:30,692 - eeg_classification - INFO - Data spans 1138.85 seconds from 2024-06-06 12:56:03.180000 to 2024-06-06 13:15:02.029000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:30,692 - eeg_classification - INFO - Data spans 1138.85 seconds from 2024-06-06 12:56:03.180000 to 2024-06-06 13:15:02.029000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,078 - eeg_classification - INFO - Sampling complete: 291576 -> 11400 data points (3.9%)\n",
      "2025-03-14 09:28:31,078 - eeg_classification - INFO - Sampling complete: 291576 -> 11400 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,078 - eeg_classification - INFO - Sampling complete: 291576 -> 11400 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,093 - eeg_classification - INFO - Preprocessing complete. Output shape: (11400, 41)\n",
      "2025-03-14 09:28:31,093 - eeg_classification - INFO - Preprocessing complete. Output shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,093 - eeg_classification - INFO - Preprocessing complete. Output shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,096 - eeg_classification - INFO - Cleaned data shape: (11400, 41)\n",
      "2025-03-14 09:28:31,096 - eeg_classification - INFO - Cleaned data shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,096 - eeg_classification - INFO - Cleaned data shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,098 - eeg_classification - INFO - Engineering features from data with shape (11400, 41)\n",
      "2025-03-14 09:28:31,098 - eeg_classification - INFO - Engineering features from data with shape (11400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,098 - eeg_classification - INFO - Engineering features from data with shape (11400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,587 - eeg_classification - INFO - Feature engineering complete. Output shape: (11400, 140)\n",
      "2025-03-14 09:28:31,587 - eeg_classification - INFO - Feature engineering complete. Output shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:31,587 - eeg_classification - INFO - Feature engineering complete. Output shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,590 - eeg_classification - INFO - Features shape: (11400, 140)\n",
      "2025-03-14 09:28:31,590 - eeg_classification - INFO - Features shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,590 - eeg_classification - INFO - Features shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,598 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:31,598 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,598 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,601 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:31,601 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,601 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,750 - eeg_classification - INFO - Processing file file_6 with 292048 rows\n",
      "2025-03-14 09:28:31,750 - eeg_classification - INFO - Processing file file_6 with 292048 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,750 - eeg_classification - INFO - Processing file file_6 with 292048 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,802 - eeg_classification - WARNING - Input data for file file_6 contains 8580 NaN values\n",
      "2025-03-14 09:28:31,802 - eeg_classification - WARNING - Input data for file file_6 contains 8580 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,802 - eeg_classification - WARNING - Input data for file file_6 contains 8580 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,804 - eeg_classification - INFO - Preprocessing data with shape (292048, 41)\n",
      "2025-03-14 09:28:31,804 - eeg_classification - INFO - Preprocessing data with shape (292048, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,804 - eeg_classification - INFO - Preprocessing data with shape (292048, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,994 - eeg_classification - WARNING - Dropping 220 rows with invalid timestamps\n",
      "2025-03-14 09:28:31,994 - eeg_classification - WARNING - Dropping 220 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:31,994 - eeg_classification - WARNING - Dropping 220 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,028 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 291828\n",
      "2025-03-14 09:28:32,028 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 291828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,028 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 291828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:32,183 - eeg_classification - INFO - Data spans 1139.78 seconds from 2024-06-06 13:58:43.265000 to 2024-06-06 14:17:43.047000\n",
      "2025-03-14 09:28:32,183 - eeg_classification - INFO - Data spans 1139.78 seconds from 2024-06-06 13:58:43.265000 to 2024-06-06 14:17:43.047000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,183 - eeg_classification - INFO - Data spans 1139.78 seconds from 2024-06-06 13:58:43.265000 to 2024-06-06 14:17:43.047000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,556 - eeg_classification - INFO - Sampling complete: 291828 -> 11400 data points (3.9%)\n",
      "2025-03-14 09:28:32,556 - eeg_classification - INFO - Sampling complete: 291828 -> 11400 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,556 - eeg_classification - INFO - Sampling complete: 291828 -> 11400 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,571 - eeg_classification - INFO - Preprocessing complete. Output shape: (11400, 41)\n",
      "2025-03-14 09:28:32,571 - eeg_classification - INFO - Preprocessing complete. Output shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,571 - eeg_classification - INFO - Preprocessing complete. Output shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,575 - eeg_classification - INFO - Cleaned data shape: (11400, 41)\n",
      "2025-03-14 09:28:32,575 - eeg_classification - INFO - Cleaned data shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,575 - eeg_classification - INFO - Cleaned data shape: (11400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,578 - eeg_classification - INFO - Engineering features from data with shape (11400, 41)\n",
      "2025-03-14 09:28:32,578 - eeg_classification - INFO - Engineering features from data with shape (11400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:32,578 - eeg_classification - INFO - Engineering features from data with shape (11400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,063 - eeg_classification - INFO - Feature engineering complete. Output shape: (11400, 140)\n",
      "2025-03-14 09:28:33,063 - eeg_classification - INFO - Feature engineering complete. Output shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:33,063 - eeg_classification - INFO - Feature engineering complete. Output shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,065 - eeg_classification - INFO - Features shape: (11400, 140)\n",
      "2025-03-14 09:28:33,065 - eeg_classification - INFO - Features shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,065 - eeg_classification - INFO - Features shape: (11400, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,074 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:33,074 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,074 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,076 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:33,076 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,076 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,214 - eeg_classification - INFO - Processing file file_7 with 212364 rows\n",
      "2025-03-14 09:28:33,214 - eeg_classification - INFO - Processing file file_7 with 212364 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,214 - eeg_classification - INFO - Processing file file_7 with 212364 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,253 - eeg_classification - WARNING - Input data for file file_7 contains 32748 NaN values\n",
      "2025-03-14 09:28:33,253 - eeg_classification - WARNING - Input data for file file_7 contains 32748 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,253 - eeg_classification - WARNING - Input data for file file_7 contains 32748 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,255 - eeg_classification - INFO - Preprocessing data with shape (212364, 41)\n",
      "2025-03-14 09:28:33,255 - eeg_classification - INFO - Preprocessing data with shape (212364, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,255 - eeg_classification - INFO - Preprocessing data with shape (212364, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,394 - eeg_classification - WARNING - Dropping 84 rows with invalid timestamps\n",
      "2025-03-14 09:28:33,394 - eeg_classification - WARNING - Dropping 84 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,394 - eeg_classification - WARNING - Dropping 84 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,421 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 212280\n",
      "2025-03-14 09:28:33,421 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 212280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,421 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 212280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:33,545 - eeg_classification - INFO - Data spans 829.11 seconds from 2024-06-12 13:38:16.259000 to 2024-06-12 13:52:05.370000\n",
      "2025-03-14 09:28:33,545 - eeg_classification - INFO - Data spans 829.11 seconds from 2024-06-12 13:38:16.259000 to 2024-06-12 13:52:05.370000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,545 - eeg_classification - INFO - Data spans 829.11 seconds from 2024-06-12 13:38:16.259000 to 2024-06-12 13:52:05.370000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,784 - eeg_classification - INFO - Sampling complete: 202152 -> 8300 data points (4.1%)\n",
      "2025-03-14 09:28:33,784 - eeg_classification - INFO - Sampling complete: 202152 -> 8300 data points (4.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,784 - eeg_classification - INFO - Sampling complete: 202152 -> 8300 data points (4.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,797 - eeg_classification - INFO - Preprocessing complete. Output shape: (8300, 41)\n",
      "2025-03-14 09:28:33,797 - eeg_classification - INFO - Preprocessing complete. Output shape: (8300, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,797 - eeg_classification - INFO - Preprocessing complete. Output shape: (8300, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,799 - eeg_classification - INFO - Cleaned data shape: (8300, 41)\n",
      "2025-03-14 09:28:33,799 - eeg_classification - INFO - Cleaned data shape: (8300, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,799 - eeg_classification - INFO - Cleaned data shape: (8300, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,801 - eeg_classification - INFO - Engineering features from data with shape (8300, 41)\n",
      "2025-03-14 09:28:33,801 - eeg_classification - INFO - Engineering features from data with shape (8300, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:33,801 - eeg_classification - INFO - Engineering features from data with shape (8300, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,219 - eeg_classification - INFO - Feature engineering complete. Output shape: (8300, 140)\n",
      "2025-03-14 09:28:34,219 - eeg_classification - INFO - Feature engineering complete. Output shape: (8300, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:34,219 - eeg_classification - INFO - Feature engineering complete. Output shape: (8300, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,221 - eeg_classification - INFO - Features shape: (8300, 140)\n",
      "2025-03-14 09:28:34,221 - eeg_classification - INFO - Features shape: (8300, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,221 - eeg_classification - INFO - Features shape: (8300, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,230 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:34,230 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,230 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,232 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:34,232 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,232 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,377 - eeg_classification - INFO - Processing file file_8 with 289170 rows\n",
      "2025-03-14 09:28:34,377 - eeg_classification - INFO - Processing file file_8 with 289170 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,377 - eeg_classification - INFO - Processing file file_8 with 289170 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,432 - eeg_classification - WARNING - Input data for file file_8 contains 23934 NaN values\n",
      "2025-03-14 09:28:34,432 - eeg_classification - WARNING - Input data for file file_8 contains 23934 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,432 - eeg_classification - WARNING - Input data for file file_8 contains 23934 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,435 - eeg_classification - INFO - Preprocessing data with shape (289170, 41)\n",
      "2025-03-14 09:28:34,435 - eeg_classification - INFO - Preprocessing data with shape (289170, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,435 - eeg_classification - INFO - Preprocessing data with shape (289170, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,619 - eeg_classification - WARNING - Dropping 174 rows with invalid timestamps\n",
      "2025-03-14 09:28:34,619 - eeg_classification - WARNING - Dropping 174 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,619 - eeg_classification - WARNING - Dropping 174 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,652 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 288996\n",
      "2025-03-14 09:28:34,652 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 288996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,652 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 288996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:34,825 - eeg_classification - INFO - Data spans 1128.90 seconds from 2024-06-12 14:22:04.024000 to 2024-06-12 14:40:52.925000\n",
      "2025-03-14 09:28:34,825 - eeg_classification - INFO - Data spans 1128.90 seconds from 2024-06-12 14:22:04.024000 to 2024-06-12 14:40:52.925000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:34,825 - eeg_classification - INFO - Data spans 1128.90 seconds from 2024-06-12 14:22:04.024000 to 2024-06-12 14:40:52.925000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,191 - eeg_classification - INFO - Sampling complete: 282744 -> 11300 data points (4.0%)\n",
      "2025-03-14 09:28:35,191 - eeg_classification - INFO - Sampling complete: 282744 -> 11300 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,191 - eeg_classification - INFO - Sampling complete: 282744 -> 11300 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,205 - eeg_classification - INFO - Preprocessing complete. Output shape: (11300, 41)\n",
      "2025-03-14 09:28:35,205 - eeg_classification - INFO - Preprocessing complete. Output shape: (11300, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,205 - eeg_classification - INFO - Preprocessing complete. Output shape: (11300, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,207 - eeg_classification - INFO - Cleaned data shape: (11300, 41)\n",
      "2025-03-14 09:28:35,207 - eeg_classification - INFO - Cleaned data shape: (11300, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,207 - eeg_classification - INFO - Cleaned data shape: (11300, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,209 - eeg_classification - INFO - Engineering features from data with shape (11300, 41)\n",
      "2025-03-14 09:28:35,209 - eeg_classification - INFO - Engineering features from data with shape (11300, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,209 - eeg_classification - INFO - Engineering features from data with shape (11300, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,736 - eeg_classification - INFO - Feature engineering complete. Output shape: (11300, 140)\n",
      "2025-03-14 09:28:35,736 - eeg_classification - INFO - Feature engineering complete. Output shape: (11300, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:35,736 - eeg_classification - INFO - Feature engineering complete. Output shape: (11300, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,740 - eeg_classification - INFO - Features shape: (11300, 140)\n",
      "2025-03-14 09:28:35,740 - eeg_classification - INFO - Features shape: (11300, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,740 - eeg_classification - INFO - Features shape: (11300, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,749 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:35,749 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,749 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,751 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:35,751 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,751 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,897 - eeg_classification - INFO - Processing file file_9 with 211172 rows\n",
      "2025-03-14 09:28:35,897 - eeg_classification - INFO - Processing file file_9 with 211172 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,897 - eeg_classification - INFO - Processing file file_9 with 211172 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,938 - eeg_classification - WARNING - Input data for file file_9 contains 1716 NaN values\n",
      "2025-03-14 09:28:35,938 - eeg_classification - WARNING - Input data for file file_9 contains 1716 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,938 - eeg_classification - WARNING - Input data for file file_9 contains 1716 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,940 - eeg_classification - INFO - Preprocessing data with shape (211172, 41)\n",
      "2025-03-14 09:28:35,940 - eeg_classification - INFO - Preprocessing data with shape (211172, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:35,940 - eeg_classification - INFO - Preprocessing data with shape (211172, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,075 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n",
      "2025-03-14 09:28:36,075 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,075 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,101 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 211128\n",
      "2025-03-14 09:28:36,101 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 211128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,101 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 211128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:36,216 - eeg_classification - INFO - Data spans 824.68 seconds from 2024-06-13 14:10:20.376000 to 2024-06-13 14:24:05.053000\n",
      "2025-03-14 09:28:36,216 - eeg_classification - INFO - Data spans 824.68 seconds from 2024-06-13 14:10:20.376000 to 2024-06-13 14:24:05.053000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,216 - eeg_classification - INFO - Data spans 824.68 seconds from 2024-06-13 14:10:20.376000 to 2024-06-13 14:24:05.053000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,443 - eeg_classification - INFO - Sampling complete: 211128 -> 8250 data points (3.9%)\n",
      "2025-03-14 09:28:36,443 - eeg_classification - INFO - Sampling complete: 211128 -> 8250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,443 - eeg_classification - INFO - Sampling complete: 211128 -> 8250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,454 - eeg_classification - INFO - Preprocessing complete. Output shape: (8250, 41)\n",
      "2025-03-14 09:28:36,454 - eeg_classification - INFO - Preprocessing complete. Output shape: (8250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,454 - eeg_classification - INFO - Preprocessing complete. Output shape: (8250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,456 - eeg_classification - INFO - Cleaned data shape: (8250, 41)\n",
      "2025-03-14 09:28:36,456 - eeg_classification - INFO - Cleaned data shape: (8250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,456 - eeg_classification - INFO - Cleaned data shape: (8250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,459 - eeg_classification - INFO - Engineering features from data with shape (8250, 41)\n",
      "2025-03-14 09:28:36,459 - eeg_classification - INFO - Engineering features from data with shape (8250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,459 - eeg_classification - INFO - Engineering features from data with shape (8250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,901 - eeg_classification - INFO - Feature engineering complete. Output shape: (8250, 140)\n",
      "2025-03-14 09:28:36,901 - eeg_classification - INFO - Feature engineering complete. Output shape: (8250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:36,901 - eeg_classification - INFO - Feature engineering complete. Output shape: (8250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,903 - eeg_classification - INFO - Features shape: (8250, 140)\n",
      "2025-03-14 09:28:36,903 - eeg_classification - INFO - Features shape: (8250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,903 - eeg_classification - INFO - Features shape: (8250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,911 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:36,911 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,911 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,914 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:36,914 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:36,914 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,061 - eeg_classification - INFO - Processing file file_10 with 423021 rows\n",
      "2025-03-14 09:28:37,061 - eeg_classification - INFO - Processing file file_10 with 423021 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,061 - eeg_classification - INFO - Processing file file_10 with 423021 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,135 - eeg_classification - WARNING - Input data for file file_10 contains 46155 NaN values\n",
      "2025-03-14 09:28:37,135 - eeg_classification - WARNING - Input data for file file_10 contains 46155 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,135 - eeg_classification - WARNING - Input data for file file_10 contains 46155 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,137 - eeg_classification - INFO - Preprocessing data with shape (423021, 41)\n",
      "2025-03-14 09:28:37,137 - eeg_classification - INFO - Preprocessing data with shape (423021, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,137 - eeg_classification - INFO - Preprocessing data with shape (423021, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,413 - eeg_classification - WARNING - Dropping 297 rows with invalid timestamps\n",
      "2025-03-14 09:28:37,413 - eeg_classification - WARNING - Dropping 297 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,413 - eeg_classification - WARNING - Dropping 297 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,461 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 422724\n",
      "2025-03-14 09:28:37,461 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 422724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,461 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 422724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:37,703 - eeg_classification - INFO - Data spans 1674.07 seconds from 2024-06-13 14:48:13.638000 to 2024-06-13 15:16:07.710000\n",
      "2025-03-14 09:28:37,703 - eeg_classification - INFO - Data spans 1674.07 seconds from 2024-06-13 14:48:13.638000 to 2024-06-13 15:16:07.710000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:37,703 - eeg_classification - INFO - Data spans 1674.07 seconds from 2024-06-13 14:48:13.638000 to 2024-06-13 15:16:07.710000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,393 - eeg_classification - INFO - Sampling complete: 408132 -> 16600 data points (4.1%)\n",
      "2025-03-14 09:28:38,393 - eeg_classification - INFO - Sampling complete: 408132 -> 16600 data points (4.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,393 - eeg_classification - INFO - Sampling complete: 408132 -> 16600 data points (4.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,411 - eeg_classification - INFO - Preprocessing complete. Output shape: (16600, 41)\n",
      "2025-03-14 09:28:38,411 - eeg_classification - INFO - Preprocessing complete. Output shape: (16600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,411 - eeg_classification - INFO - Preprocessing complete. Output shape: (16600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,415 - eeg_classification - INFO - Cleaned data shape: (16600, 41)\n",
      "2025-03-14 09:28:38,415 - eeg_classification - INFO - Cleaned data shape: (16600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,415 - eeg_classification - INFO - Cleaned data shape: (16600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,417 - eeg_classification - INFO - Engineering features from data with shape (16600, 41)\n",
      "2025-03-14 09:28:38,417 - eeg_classification - INFO - Engineering features from data with shape (16600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,417 - eeg_classification - INFO - Engineering features from data with shape (16600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,943 - eeg_classification - INFO - Feature engineering complete. Output shape: (16600, 140)\n",
      "2025-03-14 09:28:38,943 - eeg_classification - INFO - Feature engineering complete. Output shape: (16600, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:38,943 - eeg_classification - INFO - Feature engineering complete. Output shape: (16600, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,945 - eeg_classification - INFO - Features shape: (16600, 140)\n",
      "2025-03-14 09:28:38,945 - eeg_classification - INFO - Features shape: (16600, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,945 - eeg_classification - INFO - Features shape: (16600, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,956 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:38,956 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,956 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,958 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:38,958 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:38,958 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,113 - eeg_classification - INFO - Processing file file_11 with 553130 rows\n",
      "2025-03-14 09:28:39,113 - eeg_classification - INFO - Processing file file_11 with 553130 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,113 - eeg_classification - INFO - Processing file file_11 with 553130 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,215 - eeg_classification - WARNING - Input data for file file_11 contains 1242450 NaN values\n",
      "2025-03-14 09:28:39,215 - eeg_classification - WARNING - Input data for file file_11 contains 1242450 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,215 - eeg_classification - WARNING - Input data for file file_11 contains 1242450 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,217 - eeg_classification - INFO - Preprocessing data with shape (553130, 41)\n",
      "2025-03-14 09:28:39,217 - eeg_classification - INFO - Preprocessing data with shape (553130, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,217 - eeg_classification - INFO - Preprocessing data with shape (553130, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,571 - eeg_classification - WARNING - Dropping 326 rows with invalid timestamps\n",
      "2025-03-14 09:28:39,571 - eeg_classification - WARNING - Dropping 326 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,571 - eeg_classification - WARNING - Dropping 326 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,637 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 552804\n",
      "2025-03-14 09:28:39,637 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 552804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,637 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 552804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:39,821 - eeg_classification - INFO - Data spans 2158.04 seconds from 2024-06-17 21:42:37.627000 to 2024-06-17 22:18:35.666000\n",
      "2025-03-14 09:28:39,821 - eeg_classification - INFO - Data spans 2158.04 seconds from 2024-06-17 21:42:37.627000 to 2024-06-17 22:18:35.666000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:39,821 - eeg_classification - INFO - Data spans 2158.04 seconds from 2024-06-17 21:42:37.627000 to 2024-06-17 22:18:35.666000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,290 - eeg_classification - INFO - Sampling complete: 127092 -> 21600 data points (17.0%)\n",
      "2025-03-14 09:28:40,290 - eeg_classification - INFO - Sampling complete: 127092 -> 21600 data points (17.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,290 - eeg_classification - INFO - Sampling complete: 127092 -> 21600 data points (17.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,301 - eeg_classification - INFO - Preprocessing complete. Output shape: (21600, 41)\n",
      "2025-03-14 09:28:40,301 - eeg_classification - INFO - Preprocessing complete. Output shape: (21600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,301 - eeg_classification - INFO - Preprocessing complete. Output shape: (21600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,304 - eeg_classification - INFO - Cleaned data shape: (21600, 41)\n",
      "2025-03-14 09:28:40,304 - eeg_classification - INFO - Cleaned data shape: (21600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,304 - eeg_classification - INFO - Cleaned data shape: (21600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,306 - eeg_classification - INFO - Engineering features from data with shape (21600, 41)\n",
      "2025-03-14 09:28:40,306 - eeg_classification - INFO - Engineering features from data with shape (21600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,306 - eeg_classification - INFO - Engineering features from data with shape (21600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,834 - eeg_classification - INFO - Feature engineering complete. Output shape: (21600, 140)\n",
      "2025-03-14 09:28:40,834 - eeg_classification - INFO - Feature engineering complete. Output shape: (21600, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:40,834 - eeg_classification - INFO - Feature engineering complete. Output shape: (21600, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,836 - eeg_classification - INFO - Features shape: (21600, 140)\n",
      "2025-03-14 09:28:40,836 - eeg_classification - INFO - Features shape: (21600, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,836 - eeg_classification - INFO - Features shape: (21600, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,849 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:40,849 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,849 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,851 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:40,851 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,851 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,996 - eeg_classification - INFO - Processing file file_12 with 360120 rows\n",
      "2025-03-14 09:28:40,996 - eeg_classification - INFO - Processing file file_12 with 360120 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:40,996 - eeg_classification - INFO - Processing file file_12 with 360120 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,059 - eeg_classification - WARNING - Input data for file file_12 contains 12636 NaN values\n",
      "2025-03-14 09:28:41,059 - eeg_classification - WARNING - Input data for file file_12 contains 12636 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,059 - eeg_classification - WARNING - Input data for file file_12 contains 12636 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,062 - eeg_classification - INFO - Preprocessing data with shape (360120, 41)\n",
      "2025-03-14 09:28:41,062 - eeg_classification - INFO - Preprocessing data with shape (360120, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,062 - eeg_classification - INFO - Preprocessing data with shape (360120, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,376 - eeg_classification - WARNING - Dropping 324 rows with invalid timestamps\n",
      "2025-03-14 09:28:41,376 - eeg_classification - WARNING - Dropping 324 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,376 - eeg_classification - WARNING - Dropping 324 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,417 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 359796\n",
      "2025-03-14 09:28:41,417 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 359796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,417 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 359796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:41,609 - eeg_classification - INFO - Data spans 1405.33 seconds from 2024-06-18 01:31:42.357000 to 2024-06-18 01:55:07.683000\n",
      "2025-03-14 09:28:41,609 - eeg_classification - INFO - Data spans 1405.33 seconds from 2024-06-18 01:31:42.357000 to 2024-06-18 01:55:07.683000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:41,609 - eeg_classification - INFO - Data spans 1405.33 seconds from 2024-06-18 01:31:42.357000 to 2024-06-18 01:55:07.683000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,134 - eeg_classification - INFO - Sampling complete: 359796 -> 14100 data points (3.9%)\n",
      "2025-03-14 09:28:42,134 - eeg_classification - INFO - Sampling complete: 359796 -> 14100 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,134 - eeg_classification - INFO - Sampling complete: 359796 -> 14100 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,150 - eeg_classification - INFO - Preprocessing complete. Output shape: (14100, 41)\n",
      "2025-03-14 09:28:42,150 - eeg_classification - INFO - Preprocessing complete. Output shape: (14100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,150 - eeg_classification - INFO - Preprocessing complete. Output shape: (14100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,153 - eeg_classification - INFO - Cleaned data shape: (14100, 41)\n",
      "2025-03-14 09:28:42,153 - eeg_classification - INFO - Cleaned data shape: (14100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,153 - eeg_classification - INFO - Cleaned data shape: (14100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,155 - eeg_classification - INFO - Engineering features from data with shape (14100, 41)\n",
      "2025-03-14 09:28:42,155 - eeg_classification - INFO - Engineering features from data with shape (14100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,155 - eeg_classification - INFO - Engineering features from data with shape (14100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,644 - eeg_classification - INFO - Feature engineering complete. Output shape: (14100, 140)\n",
      "2025-03-14 09:28:42,644 - eeg_classification - INFO - Feature engineering complete. Output shape: (14100, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:42,644 - eeg_classification - INFO - Feature engineering complete. Output shape: (14100, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,646 - eeg_classification - INFO - Features shape: (14100, 140)\n",
      "2025-03-14 09:28:42,646 - eeg_classification - INFO - Features shape: (14100, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,646 - eeg_classification - INFO - Features shape: (14100, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,655 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:42,655 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,655 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,657 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:42,657 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,657 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,797 - eeg_classification - INFO - Processing file file_13 with 338747 rows\n",
      "2025-03-14 09:28:42,797 - eeg_classification - INFO - Processing file file_13 with 338747 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,797 - eeg_classification - INFO - Processing file file_13 with 338747 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,856 - eeg_classification - WARNING - Input data for file file_13 contains 3705 NaN values\n",
      "2025-03-14 09:28:42,856 - eeg_classification - WARNING - Input data for file file_13 contains 3705 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,856 - eeg_classification - WARNING - Input data for file file_13 contains 3705 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,858 - eeg_classification - INFO - Preprocessing data with shape (338747, 41)\n",
      "2025-03-14 09:28:42,858 - eeg_classification - INFO - Preprocessing data with shape (338747, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:42,858 - eeg_classification - INFO - Preprocessing data with shape (338747, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,118 - eeg_classification - WARNING - Dropping 95 rows with invalid timestamps\n",
      "2025-03-14 09:28:43,118 - eeg_classification - WARNING - Dropping 95 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,118 - eeg_classification - WARNING - Dropping 95 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,156 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 338652\n",
      "2025-03-14 09:28:43,156 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 338652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,156 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 338652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:43,336 - eeg_classification - INFO - Data spans 1322.67 seconds from 2024-06-19 00:37:24.749000 to 2024-06-19 00:59:27.424000\n",
      "2025-03-14 09:28:43,336 - eeg_classification - INFO - Data spans 1322.67 seconds from 2024-06-19 00:37:24.749000 to 2024-06-19 00:59:27.424000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,336 - eeg_classification - INFO - Data spans 1322.67 seconds from 2024-06-19 00:37:24.749000 to 2024-06-19 00:59:27.424000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,838 - eeg_classification - INFO - Sampling complete: 338652 -> 13250 data points (3.9%)\n",
      "2025-03-14 09:28:43,838 - eeg_classification - INFO - Sampling complete: 338652 -> 13250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,838 - eeg_classification - INFO - Sampling complete: 338652 -> 13250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,852 - eeg_classification - INFO - Preprocessing complete. Output shape: (13250, 41)\n",
      "2025-03-14 09:28:43,852 - eeg_classification - INFO - Preprocessing complete. Output shape: (13250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,852 - eeg_classification - INFO - Preprocessing complete. Output shape: (13250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,855 - eeg_classification - INFO - Cleaned data shape: (13250, 41)\n",
      "2025-03-14 09:28:43,855 - eeg_classification - INFO - Cleaned data shape: (13250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,855 - eeg_classification - INFO - Cleaned data shape: (13250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,857 - eeg_classification - INFO - Engineering features from data with shape (13250, 41)\n",
      "2025-03-14 09:28:43,857 - eeg_classification - INFO - Engineering features from data with shape (13250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:43,857 - eeg_classification - INFO - Engineering features from data with shape (13250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,345 - eeg_classification - INFO - Feature engineering complete. Output shape: (13250, 140)\n",
      "2025-03-14 09:28:44,345 - eeg_classification - INFO - Feature engineering complete. Output shape: (13250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:44,345 - eeg_classification - INFO - Feature engineering complete. Output shape: (13250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,347 - eeg_classification - INFO - Features shape: (13250, 140)\n",
      "2025-03-14 09:28:44,347 - eeg_classification - INFO - Features shape: (13250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,347 - eeg_classification - INFO - Features shape: (13250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,356 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:44,356 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,356 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,359 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:44,359 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,359 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,500 - eeg_classification - INFO - Processing file file_14 with 441352 rows\n",
      "2025-03-14 09:28:44,500 - eeg_classification - INFO - Processing file file_14 with 441352 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,500 - eeg_classification - INFO - Processing file file_14 with 441352 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,576 - eeg_classification - WARNING - Input data for file file_14 contains 9516 NaN values\n",
      "2025-03-14 09:28:44,576 - eeg_classification - WARNING - Input data for file file_14 contains 9516 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,576 - eeg_classification - WARNING - Input data for file file_14 contains 9516 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,578 - eeg_classification - INFO - Preprocessing data with shape (441352, 41)\n",
      "2025-03-14 09:28:44,578 - eeg_classification - INFO - Preprocessing data with shape (441352, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,578 - eeg_classification - INFO - Preprocessing data with shape (441352, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,857 - eeg_classification - WARNING - Dropping 244 rows with invalid timestamps\n",
      "2025-03-14 09:28:44,857 - eeg_classification - WARNING - Dropping 244 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,857 - eeg_classification - WARNING - Dropping 244 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,906 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 441108\n",
      "2025-03-14 09:28:44,906 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 441108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:44,906 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 441108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:45,135 - eeg_classification - INFO - Data spans 1722.94 seconds from 2024-06-19 10:40:52.794000 to 2024-06-19 11:09:35.737000\n",
      "2025-03-14 09:28:45,135 - eeg_classification - INFO - Data spans 1722.94 seconds from 2024-06-19 10:40:52.794000 to 2024-06-19 11:09:35.737000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,135 - eeg_classification - INFO - Data spans 1722.94 seconds from 2024-06-19 10:40:52.794000 to 2024-06-19 11:09:35.737000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,876 - eeg_classification - INFO - Sampling complete: 441108 -> 17250 data points (3.9%)\n",
      "2025-03-14 09:28:45,876 - eeg_classification - INFO - Sampling complete: 441108 -> 17250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,876 - eeg_classification - INFO - Sampling complete: 441108 -> 17250 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,896 - eeg_classification - INFO - Preprocessing complete. Output shape: (17250, 41)\n",
      "2025-03-14 09:28:45,896 - eeg_classification - INFO - Preprocessing complete. Output shape: (17250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,896 - eeg_classification - INFO - Preprocessing complete. Output shape: (17250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,899 - eeg_classification - INFO - Cleaned data shape: (17250, 41)\n",
      "2025-03-14 09:28:45,899 - eeg_classification - INFO - Cleaned data shape: (17250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,899 - eeg_classification - INFO - Cleaned data shape: (17250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,903 - eeg_classification - INFO - Engineering features from data with shape (17250, 41)\n",
      "2025-03-14 09:28:45,903 - eeg_classification - INFO - Engineering features from data with shape (17250, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:45,903 - eeg_classification - INFO - Engineering features from data with shape (17250, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,401 - eeg_classification - INFO - Feature engineering complete. Output shape: (17250, 140)\n",
      "2025-03-14 09:28:46,401 - eeg_classification - INFO - Feature engineering complete. Output shape: (17250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:46,401 - eeg_classification - INFO - Feature engineering complete. Output shape: (17250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,404 - eeg_classification - INFO - Features shape: (17250, 140)\n",
      "2025-03-14 09:28:46,404 - eeg_classification - INFO - Features shape: (17250, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,404 - eeg_classification - INFO - Features shape: (17250, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,414 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:46,414 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,414 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,416 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:46,416 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,416 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,557 - eeg_classification - INFO - Processing file file_15 with 249129 rows\n",
      "2025-03-14 09:28:46,557 - eeg_classification - INFO - Processing file file_15 with 249129 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,557 - eeg_classification - INFO - Processing file file_15 with 249129 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,606 - eeg_classification - WARNING - Input data for file file_15 contains 14259 NaN values\n",
      "2025-03-14 09:28:46,606 - eeg_classification - WARNING - Input data for file file_15 contains 14259 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,606 - eeg_classification - WARNING - Input data for file file_15 contains 14259 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,608 - eeg_classification - INFO - Preprocessing data with shape (249129, 41)\n",
      "2025-03-14 09:28:46,608 - eeg_classification - INFO - Preprocessing data with shape (249129, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,608 - eeg_classification - INFO - Preprocessing data with shape (249129, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,828 - eeg_classification - WARNING - Dropping 45 rows with invalid timestamps\n",
      "2025-03-14 09:28:46,828 - eeg_classification - WARNING - Dropping 45 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,828 - eeg_classification - WARNING - Dropping 45 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,858 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 249084\n",
      "2025-03-14 09:28:46,858 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 249084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:46,858 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 249084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:47,008 - eeg_classification - INFO - Data spans 984.40 seconds from 2024-06-20 16:28:41.300000 to 2024-06-20 16:45:05.704000\n",
      "2025-03-14 09:28:47,008 - eeg_classification - INFO - Data spans 984.40 seconds from 2024-06-20 16:28:41.300000 to 2024-06-20 16:45:05.704000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,008 - eeg_classification - INFO - Data spans 984.40 seconds from 2024-06-20 16:28:41.300000 to 2024-06-20 16:45:05.704000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,324 - eeg_classification - INFO - Sampling complete: 244692 -> 9750 data points (4.0%)\n",
      "2025-03-14 09:28:47,324 - eeg_classification - INFO - Sampling complete: 244692 -> 9750 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,324 - eeg_classification - INFO - Sampling complete: 244692 -> 9750 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,336 - eeg_classification - INFO - Preprocessing complete. Output shape: (9750, 41)\n",
      "2025-03-14 09:28:47,336 - eeg_classification - INFO - Preprocessing complete. Output shape: (9750, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,336 - eeg_classification - INFO - Preprocessing complete. Output shape: (9750, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,339 - eeg_classification - INFO - Cleaned data shape: (9750, 41)\n",
      "2025-03-14 09:28:47,339 - eeg_classification - INFO - Cleaned data shape: (9750, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,339 - eeg_classification - INFO - Cleaned data shape: (9750, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,341 - eeg_classification - INFO - Engineering features from data with shape (9750, 41)\n",
      "2025-03-14 09:28:47,341 - eeg_classification - INFO - Engineering features from data with shape (9750, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,341 - eeg_classification - INFO - Engineering features from data with shape (9750, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,857 - eeg_classification - INFO - Feature engineering complete. Output shape: (9750, 140)\n",
      "2025-03-14 09:28:47,857 - eeg_classification - INFO - Feature engineering complete. Output shape: (9750, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:47,857 - eeg_classification - INFO - Feature engineering complete. Output shape: (9750, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,861 - eeg_classification - INFO - Features shape: (9750, 140)\n",
      "2025-03-14 09:28:47,861 - eeg_classification - INFO - Features shape: (9750, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,861 - eeg_classification - INFO - Features shape: (9750, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,870 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:47,870 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,870 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,872 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:47,872 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:47,872 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,021 - eeg_classification - INFO - Processing file file_16 with 79004 rows\n",
      "2025-03-14 09:28:48,021 - eeg_classification - INFO - Processing file file_16 with 79004 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,021 - eeg_classification - INFO - Processing file file_16 with 79004 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,039 - eeg_classification - WARNING - Input data for file file_16 contains 14976 NaN values\n",
      "2025-03-14 09:28:48,039 - eeg_classification - WARNING - Input data for file file_16 contains 14976 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,039 - eeg_classification - WARNING - Input data for file file_16 contains 14976 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,041 - eeg_classification - INFO - Preprocessing data with shape (79004, 41)\n",
      "2025-03-14 09:28:48,041 - eeg_classification - INFO - Preprocessing data with shape (79004, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,041 - eeg_classification - INFO - Preprocessing data with shape (79004, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,090 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n",
      "2025-03-14 09:28:48,090 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,090 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,100 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 78960\n",
      "2025-03-14 09:28:48,100 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 78960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,100 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 78960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:48,152 - eeg_classification - INFO - Data spans 308.25 seconds from 2024-06-20 22:56:06.209000 to 2024-06-20 23:01:14.461000\n",
      "2025-03-14 09:28:48,152 - eeg_classification - INFO - Data spans 308.25 seconds from 2024-06-20 22:56:06.209000 to 2024-06-20 23:01:14.461000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,152 - eeg_classification - INFO - Data spans 308.25 seconds from 2024-06-20 22:56:06.209000 to 2024-06-20 23:01:14.461000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,217 - eeg_classification - INFO - Sampling complete: 74244 -> 3100 data points (4.2%)\n",
      "2025-03-14 09:28:48,217 - eeg_classification - INFO - Sampling complete: 74244 -> 3100 data points (4.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,217 - eeg_classification - INFO - Sampling complete: 74244 -> 3100 data points (4.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,222 - eeg_classification - INFO - Preprocessing complete. Output shape: (3100, 41)\n",
      "2025-03-14 09:28:48,222 - eeg_classification - INFO - Preprocessing complete. Output shape: (3100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,222 - eeg_classification - INFO - Preprocessing complete. Output shape: (3100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,224 - eeg_classification - INFO - Cleaned data shape: (3100, 41)\n",
      "2025-03-14 09:28:48,224 - eeg_classification - INFO - Cleaned data shape: (3100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,224 - eeg_classification - INFO - Cleaned data shape: (3100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,226 - eeg_classification - INFO - Engineering features from data with shape (3100, 41)\n",
      "2025-03-14 09:28:48,226 - eeg_classification - INFO - Engineering features from data with shape (3100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,226 - eeg_classification - INFO - Engineering features from data with shape (3100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,380 - eeg_classification - INFO - Feature engineering complete. Output shape: (3100, 140)\n",
      "2025-03-14 09:28:48,380 - eeg_classification - INFO - Feature engineering complete. Output shape: (3100, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:48,380 - eeg_classification - INFO - Feature engineering complete. Output shape: (3100, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,382 - eeg_classification - INFO - Features shape: (3100, 140)\n",
      "2025-03-14 09:28:48,382 - eeg_classification - INFO - Features shape: (3100, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,382 - eeg_classification - INFO - Features shape: (3100, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,390 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:48,390 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,390 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,392 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:48,392 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,392 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,542 - eeg_classification - INFO - Processing file file_17 with 84727 rows\n",
      "2025-03-14 09:28:48,542 - eeg_classification - INFO - Processing file file_17 with 84727 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,542 - eeg_classification - INFO - Processing file file_17 with 84727 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,560 - eeg_classification - WARNING - Input data for file file_17 contains 2613 NaN values\n",
      "2025-03-14 09:28:48,560 - eeg_classification - WARNING - Input data for file file_17 contains 2613 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,560 - eeg_classification - WARNING - Input data for file file_17 contains 2613 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,562 - eeg_classification - INFO - Preprocessing data with shape (84727, 41)\n",
      "2025-03-14 09:28:48,562 - eeg_classification - INFO - Preprocessing data with shape (84727, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,562 - eeg_classification - INFO - Preprocessing data with shape (84727, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,619 - eeg_classification - WARNING - Dropping 67 rows with invalid timestamps\n",
      "2025-03-14 09:28:48,619 - eeg_classification - WARNING - Dropping 67 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,619 - eeg_classification - WARNING - Dropping 67 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,632 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 84660\n",
      "2025-03-14 09:28:48,632 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 84660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,632 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 84660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:48,682 - eeg_classification - INFO - Data spans 330.56 seconds from 2024-06-21 00:02:00.916000 to 2024-06-21 00:07:31.473000\n",
      "2025-03-14 09:28:48,682 - eeg_classification - INFO - Data spans 330.56 seconds from 2024-06-21 00:02:00.916000 to 2024-06-21 00:07:31.473000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,682 - eeg_classification - INFO - Data spans 330.56 seconds from 2024-06-21 00:02:00.916000 to 2024-06-21 00:07:31.473000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,755 - eeg_classification - INFO - Sampling complete: 84660 -> 3350 data points (4.0%)\n",
      "2025-03-14 09:28:48,755 - eeg_classification - INFO - Sampling complete: 84660 -> 3350 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,755 - eeg_classification - INFO - Sampling complete: 84660 -> 3350 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,761 - eeg_classification - INFO - Preprocessing complete. Output shape: (3350, 41)\n",
      "2025-03-14 09:28:48,761 - eeg_classification - INFO - Preprocessing complete. Output shape: (3350, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,761 - eeg_classification - INFO - Preprocessing complete. Output shape: (3350, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,764 - eeg_classification - INFO - Cleaned data shape: (3350, 41)\n",
      "2025-03-14 09:28:48,764 - eeg_classification - INFO - Cleaned data shape: (3350, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,764 - eeg_classification - INFO - Cleaned data shape: (3350, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,765 - eeg_classification - INFO - Engineering features from data with shape (3350, 41)\n",
      "2025-03-14 09:28:48,765 - eeg_classification - INFO - Engineering features from data with shape (3350, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,765 - eeg_classification - INFO - Engineering features from data with shape (3350, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,917 - eeg_classification - INFO - Feature engineering complete. Output shape: (3350, 140)\n",
      "2025-03-14 09:28:48,917 - eeg_classification - INFO - Feature engineering complete. Output shape: (3350, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:48,917 - eeg_classification - INFO - Feature engineering complete. Output shape: (3350, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,919 - eeg_classification - INFO - Features shape: (3350, 140)\n",
      "2025-03-14 09:28:48,919 - eeg_classification - INFO - Features shape: (3350, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,919 - eeg_classification - INFO - Features shape: (3350, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,926 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:48,926 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,926 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,929 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:48,929 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:48,929 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,067 - eeg_classification - INFO - Processing file file_18 with 171598 rows\n",
      "2025-03-14 09:28:49,067 - eeg_classification - INFO - Processing file file_18 with 171598 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,067 - eeg_classification - INFO - Processing file file_18 with 171598 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,104 - eeg_classification - WARNING - Input data for file file_18 contains 17382 NaN values\n",
      "2025-03-14 09:28:49,104 - eeg_classification - WARNING - Input data for file file_18 contains 17382 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,104 - eeg_classification - WARNING - Input data for file file_18 contains 17382 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,106 - eeg_classification - INFO - Preprocessing data with shape (171598, 41)\n",
      "2025-03-14 09:28:49,106 - eeg_classification - INFO - Preprocessing data with shape (171598, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,106 - eeg_classification - INFO - Preprocessing data with shape (171598, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,216 - eeg_classification - WARNING - Dropping 190 rows with invalid timestamps\n",
      "2025-03-14 09:28:49,216 - eeg_classification - WARNING - Dropping 190 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,216 - eeg_classification - WARNING - Dropping 190 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,237 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 171408\n",
      "2025-03-14 09:28:49,237 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 171408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,237 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 171408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:49,341 - eeg_classification - INFO - Data spans 681.17 seconds from 2024-06-21 01:47:40.336000 to 2024-06-21 01:59:01.511000\n",
      "2025-03-14 09:28:49,341 - eeg_classification - INFO - Data spans 681.17 seconds from 2024-06-21 01:47:40.336000 to 2024-06-21 01:59:01.511000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,341 - eeg_classification - INFO - Data spans 681.17 seconds from 2024-06-21 01:47:40.336000 to 2024-06-21 01:59:01.511000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,514 - eeg_classification - INFO - Sampling complete: 167652 -> 6750 data points (4.0%)\n",
      "2025-03-14 09:28:49,514 - eeg_classification - INFO - Sampling complete: 167652 -> 6750 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,514 - eeg_classification - INFO - Sampling complete: 167652 -> 6750 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,525 - eeg_classification - INFO - Preprocessing complete. Output shape: (6750, 41)\n",
      "2025-03-14 09:28:49,525 - eeg_classification - INFO - Preprocessing complete. Output shape: (6750, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,525 - eeg_classification - INFO - Preprocessing complete. Output shape: (6750, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,535 - eeg_classification - INFO - Cleaned data shape: (6750, 41)\n",
      "2025-03-14 09:28:49,535 - eeg_classification - INFO - Cleaned data shape: (6750, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,535 - eeg_classification - INFO - Cleaned data shape: (6750, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,538 - eeg_classification - INFO - Engineering features from data with shape (6750, 41)\n",
      "2025-03-14 09:28:49,538 - eeg_classification - INFO - Engineering features from data with shape (6750, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,538 - eeg_classification - INFO - Engineering features from data with shape (6750, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,833 - eeg_classification - INFO - Feature engineering complete. Output shape: (6750, 140)\n",
      "2025-03-14 09:28:49,833 - eeg_classification - INFO - Feature engineering complete. Output shape: (6750, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:49,833 - eeg_classification - INFO - Feature engineering complete. Output shape: (6750, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,835 - eeg_classification - INFO - Features shape: (6750, 140)\n",
      "2025-03-14 09:28:49,835 - eeg_classification - INFO - Features shape: (6750, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,835 - eeg_classification - INFO - Features shape: (6750, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,842 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:49,842 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,842 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,844 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:49,844 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,844 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,996 - eeg_classification - INFO - Processing file file_19 with 203121 rows\n",
      "2025-03-14 09:28:49,996 - eeg_classification - INFO - Processing file file_19 with 203121 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:49,996 - eeg_classification - INFO - Processing file file_19 with 203121 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,036 - eeg_classification - WARNING - Input data for file file_19 contains 45243 NaN values\n",
      "2025-03-14 09:28:50,036 - eeg_classification - WARNING - Input data for file file_19 contains 45243 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,036 - eeg_classification - WARNING - Input data for file file_19 contains 45243 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,038 - eeg_classification - INFO - Preprocessing data with shape (203121, 41)\n",
      "2025-03-14 09:28:50,038 - eeg_classification - INFO - Preprocessing data with shape (203121, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,038 - eeg_classification - INFO - Preprocessing data with shape (203121, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,165 - eeg_classification - WARNING - Dropping 81 rows with invalid timestamps\n",
      "2025-03-14 09:28:50,165 - eeg_classification - WARNING - Dropping 81 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,165 - eeg_classification - WARNING - Dropping 81 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,190 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 203040\n",
      "2025-03-14 09:28:50,190 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 203040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,190 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 203040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:50,306 - eeg_classification - INFO - Data spans 817.96 seconds from 2024-06-21 18:29:25.067000 to 2024-06-21 18:43:03.031000\n",
      "2025-03-14 09:28:50,306 - eeg_classification - INFO - Data spans 817.96 seconds from 2024-06-21 18:29:25.067000 to 2024-06-21 18:43:03.031000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,306 - eeg_classification - INFO - Data spans 817.96 seconds from 2024-06-21 18:29:25.067000 to 2024-06-21 18:43:03.031000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,527 - eeg_classification - INFO - Sampling complete: 189588 -> 8000 data points (4.2%)\n",
      "2025-03-14 09:28:50,527 - eeg_classification - INFO - Sampling complete: 189588 -> 8000 data points (4.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,527 - eeg_classification - INFO - Sampling complete: 189588 -> 8000 data points (4.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,536 - eeg_classification - INFO - Preprocessing complete. Output shape: (8000, 41)\n",
      "2025-03-14 09:28:50,536 - eeg_classification - INFO - Preprocessing complete. Output shape: (8000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,536 - eeg_classification - INFO - Preprocessing complete. Output shape: (8000, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,538 - eeg_classification - INFO - Cleaned data shape: (8000, 41)\n",
      "2025-03-14 09:28:50,538 - eeg_classification - INFO - Cleaned data shape: (8000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,538 - eeg_classification - INFO - Cleaned data shape: (8000, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,540 - eeg_classification - INFO - Engineering features from data with shape (8000, 41)\n",
      "2025-03-14 09:28:50,540 - eeg_classification - INFO - Engineering features from data with shape (8000, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,540 - eeg_classification - INFO - Engineering features from data with shape (8000, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,958 - eeg_classification - INFO - Feature engineering complete. Output shape: (8000, 140)\n",
      "2025-03-14 09:28:50,958 - eeg_classification - INFO - Feature engineering complete. Output shape: (8000, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:50,958 - eeg_classification - INFO - Feature engineering complete. Output shape: (8000, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,960 - eeg_classification - INFO - Features shape: (8000, 140)\n",
      "2025-03-14 09:28:50,960 - eeg_classification - INFO - Features shape: (8000, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,960 - eeg_classification - INFO - Features shape: (8000, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,968 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:50,968 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,968 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,970 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:50,970 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:50,970 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,115 - eeg_classification - INFO - Processing file file_20 with 88999 rows\n",
      "2025-03-14 09:28:51,115 - eeg_classification - INFO - Processing file file_20 with 88999 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,115 - eeg_classification - INFO - Processing file file_20 with 88999 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,133 - eeg_classification - WARNING - Input data for file file_20 contains 6825 NaN values\n",
      "2025-03-14 09:28:51,133 - eeg_classification - WARNING - Input data for file file_20 contains 6825 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,133 - eeg_classification - WARNING - Input data for file file_20 contains 6825 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,136 - eeg_classification - INFO - Preprocessing data with shape (88999, 41)\n",
      "2025-03-14 09:28:51,136 - eeg_classification - INFO - Preprocessing data with shape (88999, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,136 - eeg_classification - INFO - Preprocessing data with shape (88999, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,194 - eeg_classification - WARNING - Dropping 55 rows with invalid timestamps\n",
      "2025-03-14 09:28:51,194 - eeg_classification - WARNING - Dropping 55 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,194 - eeg_classification - WARNING - Dropping 55 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,206 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 88944\n",
      "2025-03-14 09:28:51,206 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 88944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,206 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 88944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:51,265 - eeg_classification - INFO - Data spans 347.31 seconds from 2024-06-21 20:00:24.364000 to 2024-06-21 20:06:11.678000\n",
      "2025-03-14 09:28:51,265 - eeg_classification - INFO - Data spans 347.31 seconds from 2024-06-21 20:00:24.364000 to 2024-06-21 20:06:11.678000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,265 - eeg_classification - INFO - Data spans 347.31 seconds from 2024-06-21 20:00:24.364000 to 2024-06-21 20:06:11.678000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,342 - eeg_classification - INFO - Sampling complete: 87264 -> 3500 data points (4.0%)\n",
      "2025-03-14 09:28:51,342 - eeg_classification - INFO - Sampling complete: 87264 -> 3500 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,342 - eeg_classification - INFO - Sampling complete: 87264 -> 3500 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,347 - eeg_classification - INFO - Preprocessing complete. Output shape: (3500, 41)\n",
      "2025-03-14 09:28:51,347 - eeg_classification - INFO - Preprocessing complete. Output shape: (3500, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,347 - eeg_classification - INFO - Preprocessing complete. Output shape: (3500, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,349 - eeg_classification - INFO - Cleaned data shape: (3500, 41)\n",
      "2025-03-14 09:28:51,349 - eeg_classification - INFO - Cleaned data shape: (3500, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,349 - eeg_classification - INFO - Cleaned data shape: (3500, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,351 - eeg_classification - INFO - Engineering features from data with shape (3500, 41)\n",
      "2025-03-14 09:28:51,351 - eeg_classification - INFO - Engineering features from data with shape (3500, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,351 - eeg_classification - INFO - Engineering features from data with shape (3500, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,510 - eeg_classification - INFO - Feature engineering complete. Output shape: (3500, 140)\n",
      "2025-03-14 09:28:51,510 - eeg_classification - INFO - Feature engineering complete. Output shape: (3500, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:51,510 - eeg_classification - INFO - Feature engineering complete. Output shape: (3500, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,513 - eeg_classification - INFO - Features shape: (3500, 140)\n",
      "2025-03-14 09:28:51,513 - eeg_classification - INFO - Features shape: (3500, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,513 - eeg_classification - INFO - Features shape: (3500, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,520 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:51,520 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,520 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,522 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:51,522 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,522 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,661 - eeg_classification - INFO - Processing file file_21 with 141023 rows\n",
      "2025-03-14 09:28:51,661 - eeg_classification - INFO - Processing file file_21 with 141023 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,661 - eeg_classification - INFO - Processing file file_21 with 141023 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,691 - eeg_classification - WARNING - Input data for file file_21 contains 180033 NaN values\n",
      "2025-03-14 09:28:51,691 - eeg_classification - WARNING - Input data for file file_21 contains 180033 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,691 - eeg_classification - WARNING - Input data for file file_21 contains 180033 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,694 - eeg_classification - INFO - Preprocessing data with shape (141023, 41)\n",
      "2025-03-14 09:28:51,694 - eeg_classification - INFO - Preprocessing data with shape (141023, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,694 - eeg_classification - INFO - Preprocessing data with shape (141023, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,776 - eeg_classification - WARNING - Dropping 47 rows with invalid timestamps\n",
      "2025-03-14 09:28:51,776 - eeg_classification - WARNING - Dropping 47 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,776 - eeg_classification - WARNING - Dropping 47 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,794 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 140976\n",
      "2025-03-14 09:28:51,794 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 140976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,794 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 140976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:51,861 - eeg_classification - INFO - Data spans 549.91 seconds from 2024-06-21 21:59:52.848000 to 2024-06-21 22:09:02.759000\n",
      "2025-03-14 09:28:51,861 - eeg_classification - INFO - Data spans 549.91 seconds from 2024-06-21 21:59:52.848000 to 2024-06-21 22:09:02.759000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,861 - eeg_classification - INFO - Data spans 549.91 seconds from 2024-06-21 21:59:52.848000 to 2024-06-21 22:09:02.759000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,966 - eeg_classification - INFO - Sampling complete: 77244 -> 5500 data points (7.1%)\n",
      "2025-03-14 09:28:51,966 - eeg_classification - INFO - Sampling complete: 77244 -> 5500 data points (7.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,966 - eeg_classification - INFO - Sampling complete: 77244 -> 5500 data points (7.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,973 - eeg_classification - INFO - Preprocessing complete. Output shape: (5500, 41)\n",
      "2025-03-14 09:28:51,973 - eeg_classification - INFO - Preprocessing complete. Output shape: (5500, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,973 - eeg_classification - INFO - Preprocessing complete. Output shape: (5500, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,975 - eeg_classification - INFO - Cleaned data shape: (5500, 41)\n",
      "2025-03-14 09:28:51,975 - eeg_classification - INFO - Cleaned data shape: (5500, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,975 - eeg_classification - INFO - Cleaned data shape: (5500, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,976 - eeg_classification - INFO - Engineering features from data with shape (5500, 41)\n",
      "2025-03-14 09:28:51,976 - eeg_classification - INFO - Engineering features from data with shape (5500, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:51,976 - eeg_classification - INFO - Engineering features from data with shape (5500, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,262 - eeg_classification - INFO - Feature engineering complete. Output shape: (5500, 140)\n",
      "2025-03-14 09:28:52,262 - eeg_classification - INFO - Feature engineering complete. Output shape: (5500, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:52,262 - eeg_classification - INFO - Feature engineering complete. Output shape: (5500, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,264 - eeg_classification - INFO - Features shape: (5500, 140)\n",
      "2025-03-14 09:28:52,264 - eeg_classification - INFO - Features shape: (5500, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,264 - eeg_classification - INFO - Features shape: (5500, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,271 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:52,271 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,271 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,274 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:52,274 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,274 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,415 - eeg_classification - INFO - Processing file file_22 with 128608 rows\n",
      "2025-03-14 09:28:52,415 - eeg_classification - INFO - Processing file file_22 with 128608 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,415 - eeg_classification - INFO - Processing file file_22 with 128608 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,444 - eeg_classification - WARNING - Input data for file file_22 contains 112452 NaN values\n",
      "2025-03-14 09:28:52,444 - eeg_classification - WARNING - Input data for file file_22 contains 112452 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,444 - eeg_classification - WARNING - Input data for file file_22 contains 112452 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,445 - eeg_classification - INFO - Preprocessing data with shape (128608, 41)\n",
      "2025-03-14 09:28:52,445 - eeg_classification - INFO - Preprocessing data with shape (128608, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,445 - eeg_classification - INFO - Preprocessing data with shape (128608, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,522 - eeg_classification - WARNING - Dropping 76 rows with invalid timestamps\n",
      "2025-03-14 09:28:52,522 - eeg_classification - WARNING - Dropping 76 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,522 - eeg_classification - WARNING - Dropping 76 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,540 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 128532\n",
      "2025-03-14 09:28:52,540 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 128532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,540 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 128532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:52,609 - eeg_classification - INFO - Data spans 531.95 seconds from 2024-06-21 22:22:27.579000 to 2024-06-21 22:31:19.533000\n",
      "2025-03-14 09:28:52,609 - eeg_classification - INFO - Data spans 531.95 seconds from 2024-06-21 22:22:27.579000 to 2024-06-21 22:31:19.533000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,609 - eeg_classification - INFO - Data spans 531.95 seconds from 2024-06-21 22:22:27.579000 to 2024-06-21 22:31:19.533000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,721 - eeg_classification - INFO - Sampling complete: 101808 -> 5094 data points (5.0%)\n",
      "2025-03-14 09:28:52,721 - eeg_classification - INFO - Sampling complete: 101808 -> 5094 data points (5.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,721 - eeg_classification - INFO - Sampling complete: 101808 -> 5094 data points (5.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,728 - eeg_classification - INFO - Preprocessing complete. Output shape: (5094, 41)\n",
      "2025-03-14 09:28:52,728 - eeg_classification - INFO - Preprocessing complete. Output shape: (5094, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,728 - eeg_classification - INFO - Preprocessing complete. Output shape: (5094, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,731 - eeg_classification - INFO - Cleaned data shape: (5094, 41)\n",
      "2025-03-14 09:28:52,731 - eeg_classification - INFO - Cleaned data shape: (5094, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,731 - eeg_classification - INFO - Cleaned data shape: (5094, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,732 - eeg_classification - INFO - Engineering features from data with shape (5094, 41)\n",
      "2025-03-14 09:28:52,732 - eeg_classification - INFO - Engineering features from data with shape (5094, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,732 - eeg_classification - INFO - Engineering features from data with shape (5094, 41)\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,938 - eeg_classification - INFO - Feature engineering complete. Output shape: (5094, 140)\n",
      "2025-03-14 09:28:52,938 - eeg_classification - INFO - Feature engineering complete. Output shape: (5094, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:52,938 - eeg_classification - INFO - Feature engineering complete. Output shape: (5094, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,939 - eeg_classification - INFO - Features shape: (5094, 140)\n",
      "2025-03-14 09:28:52,939 - eeg_classification - INFO - Features shape: (5094, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,939 - eeg_classification - INFO - Features shape: (5094, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,948 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:52,948 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,948 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,952 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:52,952 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:52,952 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,096 - eeg_classification - INFO - Processing file file_23 with 259120 rows\n",
      "2025-03-14 09:28:53,096 - eeg_classification - INFO - Processing file file_23 with 259120 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,096 - eeg_classification - INFO - Processing file file_23 with 259120 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,145 - eeg_classification - WARNING - Input data for file file_23 contains 6408 NaN values\n",
      "2025-03-14 09:28:53,145 - eeg_classification - WARNING - Input data for file file_23 contains 6408 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,145 - eeg_classification - WARNING - Input data for file file_23 contains 6408 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,147 - eeg_classification - INFO - Preprocessing data with shape (259120, 41)\n",
      "2025-03-14 09:28:53,147 - eeg_classification - INFO - Preprocessing data with shape (259120, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,147 - eeg_classification - INFO - Preprocessing data with shape (259120, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,318 - eeg_classification - WARNING - Dropping 52 rows with invalid timestamps\n",
      "2025-03-14 09:28:53,318 - eeg_classification - WARNING - Dropping 52 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,318 - eeg_classification - WARNING - Dropping 52 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,348 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 259068\n",
      "2025-03-14 09:28:53,348 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 259068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,348 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 259068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:53,502 - eeg_classification - INFO - Data spans 1011.85 seconds from 2024-06-21 23:10:14.594000 to 2024-06-21 23:27:06.448000\n",
      "2025-03-14 09:28:53,502 - eeg_classification - INFO - Data spans 1011.85 seconds from 2024-06-21 23:10:14.594000 to 2024-06-21 23:27:06.448000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,502 - eeg_classification - INFO - Data spans 1011.85 seconds from 2024-06-21 23:10:14.594000 to 2024-06-21 23:27:06.448000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,813 - eeg_classification - INFO - Sampling complete: 257376 -> 10150 data points (3.9%)\n",
      "2025-03-14 09:28:53,813 - eeg_classification - INFO - Sampling complete: 257376 -> 10150 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,813 - eeg_classification - INFO - Sampling complete: 257376 -> 10150 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,826 - eeg_classification - INFO - Preprocessing complete. Output shape: (10150, 41)\n",
      "2025-03-14 09:28:53,826 - eeg_classification - INFO - Preprocessing complete. Output shape: (10150, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,826 - eeg_classification - INFO - Preprocessing complete. Output shape: (10150, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,828 - eeg_classification - INFO - Cleaned data shape: (10150, 41)\n",
      "2025-03-14 09:28:53,828 - eeg_classification - INFO - Cleaned data shape: (10150, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,828 - eeg_classification - INFO - Cleaned data shape: (10150, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,829 - eeg_classification - INFO - Engineering features from data with shape (10150, 41)\n",
      "2025-03-14 09:28:53,829 - eeg_classification - INFO - Engineering features from data with shape (10150, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:53,829 - eeg_classification - INFO - Engineering features from data with shape (10150, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,295 - eeg_classification - INFO - Feature engineering complete. Output shape: (10150, 140)\n",
      "2025-03-14 09:28:54,295 - eeg_classification - INFO - Feature engineering complete. Output shape: (10150, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:54,295 - eeg_classification - INFO - Feature engineering complete. Output shape: (10150, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,297 - eeg_classification - INFO - Features shape: (10150, 140)\n",
      "2025-03-14 09:28:54,297 - eeg_classification - INFO - Features shape: (10150, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,297 - eeg_classification - INFO - Features shape: (10150, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,306 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:54,306 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,306 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,308 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:54,308 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,308 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,460 - eeg_classification - INFO - Processing file file_24 with 235662 rows\n",
      "2025-03-14 09:28:54,460 - eeg_classification - INFO - Processing file file_24 with 235662 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,460 - eeg_classification - INFO - Processing file file_24 with 235662 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,503 - eeg_classification - WARNING - Input data for file file_24 contains 22026 NaN values\n",
      "2025-03-14 09:28:54,503 - eeg_classification - WARNING - Input data for file file_24 contains 22026 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,503 - eeg_classification - WARNING - Input data for file file_24 contains 22026 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,505 - eeg_classification - INFO - Preprocessing data with shape (235662, 41)\n",
      "2025-03-14 09:28:54,505 - eeg_classification - INFO - Preprocessing data with shape (235662, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,505 - eeg_classification - INFO - Preprocessing data with shape (235662, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,655 - eeg_classification - WARNING - Dropping 78 rows with invalid timestamps\n",
      "2025-03-14 09:28:54,655 - eeg_classification - WARNING - Dropping 78 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,655 - eeg_classification - WARNING - Dropping 78 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,683 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 235584\n",
      "2025-03-14 09:28:54,683 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 235584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,683 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 235584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:54,819 - eeg_classification - INFO - Data spans 919.97 seconds from 2024-06-22 00:04:51.260000 to 2024-06-22 00:20:11.229000\n",
      "2025-03-14 09:28:54,819 - eeg_classification - INFO - Data spans 919.97 seconds from 2024-06-22 00:04:51.260000 to 2024-06-22 00:20:11.229000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:54,819 - eeg_classification - INFO - Data spans 919.97 seconds from 2024-06-22 00:04:51.260000 to 2024-06-22 00:20:11.229000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,157 - eeg_classification - INFO - Sampling complete: 229764 -> 9200 data points (4.0%)\n",
      "2025-03-14 09:28:55,157 - eeg_classification - INFO - Sampling complete: 229764 -> 9200 data points (4.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,157 - eeg_classification - INFO - Sampling complete: 229764 -> 9200 data points (4.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,169 - eeg_classification - INFO - Preprocessing complete. Output shape: (9200, 41)\n",
      "2025-03-14 09:28:55,169 - eeg_classification - INFO - Preprocessing complete. Output shape: (9200, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,169 - eeg_classification - INFO - Preprocessing complete. Output shape: (9200, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,171 - eeg_classification - INFO - Cleaned data shape: (9200, 41)\n",
      "2025-03-14 09:28:55,171 - eeg_classification - INFO - Cleaned data shape: (9200, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,171 - eeg_classification - INFO - Cleaned data shape: (9200, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,173 - eeg_classification - INFO - Engineering features from data with shape (9200, 41)\n",
      "2025-03-14 09:28:55,173 - eeg_classification - INFO - Engineering features from data with shape (9200, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,173 - eeg_classification - INFO - Engineering features from data with shape (9200, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,626 - eeg_classification - INFO - Feature engineering complete. Output shape: (9200, 140)\n",
      "2025-03-14 09:28:55,626 - eeg_classification - INFO - Feature engineering complete. Output shape: (9200, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:55,626 - eeg_classification - INFO - Feature engineering complete. Output shape: (9200, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,628 - eeg_classification - INFO - Features shape: (9200, 140)\n",
      "2025-03-14 09:28:55,628 - eeg_classification - INFO - Features shape: (9200, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,628 - eeg_classification - INFO - Features shape: (9200, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,635 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:55,635 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,635 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,638 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:55,638 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,638 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,785 - eeg_classification - INFO - Processing file file_25 with 431113 rows\n",
      "2025-03-14 09:28:55,785 - eeg_classification - INFO - Processing file file_25 with 431113 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,785 - eeg_classification - INFO - Processing file file_25 with 431113 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,864 - eeg_classification - WARNING - Input data for file file_25 contains 155259 NaN values\n",
      "2025-03-14 09:28:55,864 - eeg_classification - WARNING - Input data for file file_25 contains 155259 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,864 - eeg_classification - WARNING - Input data for file file_25 contains 155259 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,867 - eeg_classification - INFO - Preprocessing data with shape (431113, 41)\n",
      "2025-03-14 09:28:55,867 - eeg_classification - INFO - Preprocessing data with shape (431113, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:55,867 - eeg_classification - INFO - Preprocessing data with shape (431113, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:56,141 - eeg_classification - WARNING - Dropping 109 rows with invalid timestamps\n",
      "2025-03-14 09:28:56,141 - eeg_classification - WARNING - Dropping 109 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:56,141 - eeg_classification - WARNING - Dropping 109 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:56,193 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 431004\n",
      "2025-03-14 09:28:56,193 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 431004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:56,193 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 431004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:56,417 - eeg_classification - INFO - Data spans 1683.41 seconds from 2024-06-22 00:32:26.115000 to 2024-06-22 01:00:29.529000\n",
      "2025-03-14 09:28:56,417 - eeg_classification - INFO - Data spans 1683.41 seconds from 2024-06-22 00:32:26.115000 to 2024-06-22 01:00:29.529000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:56,417 - eeg_classification - INFO - Data spans 1683.41 seconds from 2024-06-22 00:32:26.115000 to 2024-06-22 01:00:29.529000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,065 - eeg_classification - INFO - Sampling complete: 370440 -> 16850 data points (4.5%)\n",
      "2025-03-14 09:28:57,065 - eeg_classification - INFO - Sampling complete: 370440 -> 16850 data points (4.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,065 - eeg_classification - INFO - Sampling complete: 370440 -> 16850 data points (4.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,083 - eeg_classification - INFO - Preprocessing complete. Output shape: (16850, 41)\n",
      "2025-03-14 09:28:57,083 - eeg_classification - INFO - Preprocessing complete. Output shape: (16850, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,083 - eeg_classification - INFO - Preprocessing complete. Output shape: (16850, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,086 - eeg_classification - INFO - Cleaned data shape: (16850, 41)\n",
      "2025-03-14 09:28:57,086 - eeg_classification - INFO - Cleaned data shape: (16850, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,086 - eeg_classification - INFO - Cleaned data shape: (16850, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,088 - eeg_classification - INFO - Engineering features from data with shape (16850, 41)\n",
      "2025-03-14 09:28:57,088 - eeg_classification - INFO - Engineering features from data with shape (16850, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,088 - eeg_classification - INFO - Engineering features from data with shape (16850, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,593 - eeg_classification - INFO - Feature engineering complete. Output shape: (16850, 140)\n",
      "2025-03-14 09:28:57,593 - eeg_classification - INFO - Feature engineering complete. Output shape: (16850, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:57,593 - eeg_classification - INFO - Feature engineering complete. Output shape: (16850, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,595 - eeg_classification - INFO - Features shape: (16850, 140)\n",
      "2025-03-14 09:28:57,595 - eeg_classification - INFO - Features shape: (16850, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,595 - eeg_classification - INFO - Features shape: (16850, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,606 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:57,606 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,606 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,608 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:57,608 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,608 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,757 - eeg_classification - INFO - Processing file file_26 with 130070 rows\n",
      "2025-03-14 09:28:57,757 - eeg_classification - INFO - Processing file file_26 with 130070 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,757 - eeg_classification - INFO - Processing file file_26 with 130070 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,788 - eeg_classification - WARNING - Input data for file file_26 contains 2418 NaN values\n",
      "2025-03-14 09:28:57,788 - eeg_classification - WARNING - Input data for file file_26 contains 2418 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,788 - eeg_classification - WARNING - Input data for file file_26 contains 2418 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,791 - eeg_classification - INFO - Preprocessing data with shape (130070, 41)\n",
      "2025-03-14 09:28:57,791 - eeg_classification - INFO - Preprocessing data with shape (130070, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,791 - eeg_classification - INFO - Preprocessing data with shape (130070, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,890 - eeg_classification - WARNING - Dropping 62 rows with invalid timestamps\n",
      "2025-03-14 09:28:57,890 - eeg_classification - WARNING - Dropping 62 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,890 - eeg_classification - WARNING - Dropping 62 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,910 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 130008\n",
      "2025-03-14 09:28:57,910 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 130008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,910 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 130008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:57,990 - eeg_classification - INFO - Data spans 507.65 seconds from 2024-06-22 18:29:43.337000 to 2024-06-22 18:38:10.986000\n",
      "2025-03-14 09:28:57,990 - eeg_classification - INFO - Data spans 507.65 seconds from 2024-06-22 18:29:43.337000 to 2024-06-22 18:38:10.986000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:57,990 - eeg_classification - INFO - Data spans 507.65 seconds from 2024-06-22 18:29:43.337000 to 2024-06-22 18:38:10.986000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,112 - eeg_classification - INFO - Sampling complete: 130008 -> 5100 data points (3.9%)\n",
      "2025-03-14 09:28:58,112 - eeg_classification - INFO - Sampling complete: 130008 -> 5100 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,112 - eeg_classification - INFO - Sampling complete: 130008 -> 5100 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,120 - eeg_classification - INFO - Preprocessing complete. Output shape: (5100, 41)\n",
      "2025-03-14 09:28:58,120 - eeg_classification - INFO - Preprocessing complete. Output shape: (5100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,120 - eeg_classification - INFO - Preprocessing complete. Output shape: (5100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,122 - eeg_classification - INFO - Cleaned data shape: (5100, 41)\n",
      "2025-03-14 09:28:58,122 - eeg_classification - INFO - Cleaned data shape: (5100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,122 - eeg_classification - INFO - Cleaned data shape: (5100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,124 - eeg_classification - INFO - Engineering features from data with shape (5100, 41)\n",
      "2025-03-14 09:28:58,124 - eeg_classification - INFO - Engineering features from data with shape (5100, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,124 - eeg_classification - INFO - Engineering features from data with shape (5100, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,386 - eeg_classification - INFO - Feature engineering complete. Output shape: (5100, 140)\n",
      "2025-03-14 09:28:58,386 - eeg_classification - INFO - Feature engineering complete. Output shape: (5100, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:58,386 - eeg_classification - INFO - Feature engineering complete. Output shape: (5100, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,389 - eeg_classification - INFO - Features shape: (5100, 140)\n",
      "2025-03-14 09:28:58,389 - eeg_classification - INFO - Features shape: (5100, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,389 - eeg_classification - INFO - Features shape: (5100, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,398 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:58,398 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,398 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,401 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:58,401 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,401 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,581 - eeg_classification - INFO - Processing file file_27 with 116708 rows\n",
      "2025-03-14 09:28:58,581 - eeg_classification - INFO - Processing file file_27 with 116708 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,581 - eeg_classification - INFO - Processing file file_27 with 116708 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,616 - eeg_classification - WARNING - Input data for file file_27 contains 1716 NaN values\n",
      "2025-03-14 09:28:58,616 - eeg_classification - WARNING - Input data for file file_27 contains 1716 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,616 - eeg_classification - WARNING - Input data for file file_27 contains 1716 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,620 - eeg_classification - INFO - Preprocessing data with shape (116708, 41)\n",
      "2025-03-14 09:28:58,620 - eeg_classification - INFO - Preprocessing data with shape (116708, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,620 - eeg_classification - INFO - Preprocessing data with shape (116708, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,803 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n",
      "2025-03-14 09:28:58,803 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,803 - eeg_classification - WARNING - Dropping 44 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,822 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 116664\n",
      "2025-03-14 09:28:58,822 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 116664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,822 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 116664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:58,913 - eeg_classification - INFO - Data spans 455.66 seconds from 2024-06-22 18:41:35.089000 to 2024-06-22 18:49:10.749000\n",
      "2025-03-14 09:28:58,913 - eeg_classification - INFO - Data spans 455.66 seconds from 2024-06-22 18:41:35.089000 to 2024-06-22 18:49:10.749000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:58,913 - eeg_classification - INFO - Data spans 455.66 seconds from 2024-06-22 18:41:35.089000 to 2024-06-22 18:49:10.749000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,030 - eeg_classification - INFO - Sampling complete: 116664 -> 4600 data points (3.9%)\n",
      "2025-03-14 09:28:59,030 - eeg_classification - INFO - Sampling complete: 116664 -> 4600 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,030 - eeg_classification - INFO - Sampling complete: 116664 -> 4600 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,038 - eeg_classification - INFO - Preprocessing complete. Output shape: (4600, 41)\n",
      "2025-03-14 09:28:59,038 - eeg_classification - INFO - Preprocessing complete. Output shape: (4600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,038 - eeg_classification - INFO - Preprocessing complete. Output shape: (4600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,041 - eeg_classification - INFO - Cleaned data shape: (4600, 41)\n",
      "2025-03-14 09:28:59,041 - eeg_classification - INFO - Cleaned data shape: (4600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,041 - eeg_classification - INFO - Cleaned data shape: (4600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,043 - eeg_classification - INFO - Engineering features from data with shape (4600, 41)\n",
      "2025-03-14 09:28:59,043 - eeg_classification - INFO - Engineering features from data with shape (4600, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,043 - eeg_classification - INFO - Engineering features from data with shape (4600, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,322 - eeg_classification - INFO - Feature engineering complete. Output shape: (4600, 140)\n",
      "2025-03-14 09:28:59,322 - eeg_classification - INFO - Feature engineering complete. Output shape: (4600, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:28:59,322 - eeg_classification - INFO - Feature engineering complete. Output shape: (4600, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,325 - eeg_classification - INFO - Features shape: (4600, 140)\n",
      "2025-03-14 09:28:59,325 - eeg_classification - INFO - Features shape: (4600, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,325 - eeg_classification - INFO - Features shape: (4600, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,335 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:28:59,335 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,335 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,337 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:28:59,337 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,337 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,505 - eeg_classification - INFO - Processing file file_28 with 100713 rows\n",
      "2025-03-14 09:28:59,505 - eeg_classification - INFO - Processing file file_28 with 100713 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,505 - eeg_classification - INFO - Processing file file_28 with 100713 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,532 - eeg_classification - WARNING - Input data for file file_28 contains 1443 NaN values\n",
      "2025-03-14 09:28:59,532 - eeg_classification - WARNING - Input data for file file_28 contains 1443 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,532 - eeg_classification - WARNING - Input data for file file_28 contains 1443 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,534 - eeg_classification - INFO - Preprocessing data with shape (100713, 41)\n",
      "2025-03-14 09:28:59,534 - eeg_classification - INFO - Preprocessing data with shape (100713, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,534 - eeg_classification - INFO - Preprocessing data with shape (100713, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,610 - eeg_classification - WARNING - Dropping 33 rows with invalid timestamps\n",
      "2025-03-14 09:28:59,610 - eeg_classification - WARNING - Dropping 33 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,610 - eeg_classification - WARNING - Dropping 33 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,625 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 100680\n",
      "2025-03-14 09:28:59,625 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 100680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,625 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 100680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:28:59,695 - eeg_classification - INFO - Data spans 393.18 seconds from 2024-06-22 18:50:07.373000 to 2024-06-22 18:56:40.556000\n",
      "2025-03-14 09:28:59,695 - eeg_classification - INFO - Data spans 393.18 seconds from 2024-06-22 18:50:07.373000 to 2024-06-22 18:56:40.556000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,695 - eeg_classification - INFO - Data spans 393.18 seconds from 2024-06-22 18:50:07.373000 to 2024-06-22 18:56:40.556000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,795 - eeg_classification - INFO - Sampling complete: 100548 -> 3950 data points (3.9%)\n",
      "2025-03-14 09:28:59,795 - eeg_classification - INFO - Sampling complete: 100548 -> 3950 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,795 - eeg_classification - INFO - Sampling complete: 100548 -> 3950 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,803 - eeg_classification - INFO - Preprocessing complete. Output shape: (3950, 41)\n",
      "2025-03-14 09:28:59,803 - eeg_classification - INFO - Preprocessing complete. Output shape: (3950, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,803 - eeg_classification - INFO - Preprocessing complete. Output shape: (3950, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,806 - eeg_classification - INFO - Cleaned data shape: (3950, 41)\n",
      "2025-03-14 09:28:59,806 - eeg_classification - INFO - Cleaned data shape: (3950, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,806 - eeg_classification - INFO - Cleaned data shape: (3950, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,809 - eeg_classification - INFO - Engineering features from data with shape (3950, 41)\n",
      "2025-03-14 09:28:59,809 - eeg_classification - INFO - Engineering features from data with shape (3950, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:28:59,809 - eeg_classification - INFO - Engineering features from data with shape (3950, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,044 - eeg_classification - INFO - Feature engineering complete. Output shape: (3950, 140)\n",
      "2025-03-14 09:29:00,044 - eeg_classification - INFO - Feature engineering complete. Output shape: (3950, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:29:00,044 - eeg_classification - INFO - Feature engineering complete. Output shape: (3950, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,047 - eeg_classification - INFO - Features shape: (3950, 140)\n",
      "2025-03-14 09:29:00,047 - eeg_classification - INFO - Features shape: (3950, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,047 - eeg_classification - INFO - Features shape: (3950, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,055 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:29:00,055 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,055 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,058 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:29:00,058 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,058 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,232 - eeg_classification - INFO - Processing file file_29 with 125929 rows\n",
      "2025-03-14 09:29:00,232 - eeg_classification - INFO - Processing file file_29 with 125929 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,232 - eeg_classification - INFO - Processing file file_29 with 125929 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,262 - eeg_classification - WARNING - Input data for file file_29 contains 2079 NaN values\n",
      "2025-03-14 09:29:00,262 - eeg_classification - WARNING - Input data for file file_29 contains 2079 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,262 - eeg_classification - WARNING - Input data for file file_29 contains 2079 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,265 - eeg_classification - INFO - Preprocessing data with shape (125929, 41)\n",
      "2025-03-14 09:29:00,265 - eeg_classification - INFO - Preprocessing data with shape (125929, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,265 - eeg_classification - INFO - Preprocessing data with shape (125929, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,356 - eeg_classification - WARNING - Dropping 49 rows with invalid timestamps\n",
      "2025-03-14 09:29:00,356 - eeg_classification - WARNING - Dropping 49 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,356 - eeg_classification - WARNING - Dropping 49 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,375 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 125880\n",
      "2025-03-14 09:29:00,375 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 125880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,375 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 125880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:29:00,492 - eeg_classification - INFO - Data spans 491.72 seconds from 2024-06-22 18:57:07.892000 to 2024-06-22 19:05:19.611000\n",
      "2025-03-14 09:29:00,492 - eeg_classification - INFO - Data spans 491.72 seconds from 2024-06-22 18:57:07.892000 to 2024-06-22 19:05:19.611000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,492 - eeg_classification - INFO - Data spans 491.72 seconds from 2024-06-22 18:57:07.892000 to 2024-06-22 19:05:19.611000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,685 - eeg_classification - INFO - Sampling complete: 125748 -> 4950 data points (3.9%)\n",
      "2025-03-14 09:29:00,685 - eeg_classification - INFO - Sampling complete: 125748 -> 4950 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,685 - eeg_classification - INFO - Sampling complete: 125748 -> 4950 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,696 - eeg_classification - INFO - Preprocessing complete. Output shape: (4950, 41)\n",
      "2025-03-14 09:29:00,696 - eeg_classification - INFO - Preprocessing complete. Output shape: (4950, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,696 - eeg_classification - INFO - Preprocessing complete. Output shape: (4950, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,700 - eeg_classification - INFO - Cleaned data shape: (4950, 41)\n",
      "2025-03-14 09:29:00,700 - eeg_classification - INFO - Cleaned data shape: (4950, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,700 - eeg_classification - INFO - Cleaned data shape: (4950, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,702 - eeg_classification - INFO - Engineering features from data with shape (4950, 41)\n",
      "2025-03-14 09:29:00,702 - eeg_classification - INFO - Engineering features from data with shape (4950, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,702 - eeg_classification - INFO - Engineering features from data with shape (4950, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,931 - eeg_classification - INFO - Feature engineering complete. Output shape: (4950, 140)\n",
      "2025-03-14 09:29:00,931 - eeg_classification - INFO - Feature engineering complete. Output shape: (4950, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:29:00,931 - eeg_classification - INFO - Feature engineering complete. Output shape: (4950, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,933 - eeg_classification - INFO - Features shape: (4950, 140)\n",
      "2025-03-14 09:29:00,933 - eeg_classification - INFO - Features shape: (4950, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,933 - eeg_classification - INFO - Features shape: (4950, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,940 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:29:00,940 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,940 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,943 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:29:00,943 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:00,943 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,102 - eeg_classification - INFO - Processing file file_30 with 367961 rows\n",
      "2025-03-14 09:29:01,102 - eeg_classification - INFO - Processing file file_30 with 367961 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,102 - eeg_classification - INFO - Processing file file_30 with 367961 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,166 - eeg_classification - WARNING - Input data for file file_30 contains 11427 NaN values\n",
      "2025-03-14 09:29:01,166 - eeg_classification - WARNING - Input data for file file_30 contains 11427 NaN values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,166 - eeg_classification - WARNING - Input data for file file_30 contains 11427 NaN values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,168 - eeg_classification - INFO - Preprocessing data with shape (367961, 41)\n",
      "2025-03-14 09:29:01,168 - eeg_classification - INFO - Preprocessing data with shape (367961, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,168 - eeg_classification - INFO - Preprocessing data with shape (367961, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,481 - eeg_classification - WARNING - Dropping 293 rows with invalid timestamps\n",
      "2025-03-14 09:29:01,481 - eeg_classification - WARNING - Dropping 293 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,481 - eeg_classification - WARNING - Dropping 293 rows with invalid timestamps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,530 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 367668\n",
      "2025-03-14 09:29:01,530 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 367668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,530 - eeg_classification - INFO - Successfully converted timestamps. Remaining rows: 367668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in numeric columns: TimeStamp          0\n",
      "Delta_TP9          0\n",
      "Delta_AF7          0\n",
      "Delta_AF8          0\n",
      "Delta_TP10         0\n",
      "Theta_TP9          0\n",
      "Theta_AF7          0\n",
      "Theta_AF8          0\n",
      "Theta_TP10         0\n",
      "Alpha_TP9          0\n",
      "Alpha_AF7          0\n",
      "Alpha_AF8          0\n",
      "Alpha_TP10         0\n",
      "Beta_TP9           0\n",
      "Beta_AF7           0\n",
      "Beta_AF8           0\n",
      "Beta_TP10          0\n",
      "Gamma_TP9          0\n",
      "Gamma_AF7          0\n",
      "Gamma_AF8          0\n",
      "Gamma_TP10         0\n",
      "RAW_TP9            0\n",
      "RAW_AF7            0\n",
      "RAW_AF8            0\n",
      "RAW_TP10           0\n",
      "AUX_RIGHT          0\n",
      "Mellow             0\n",
      "Concentration      0\n",
      "Accelerometer_X    0\n",
      "Accelerometer_Y    0\n",
      "Accelerometer_Z    0\n",
      "Gyro_X             0\n",
      "Gyro_Y             0\n",
      "Gyro_Z             0\n",
      "HeadBandOn         0\n",
      "HSI_TP9            0\n",
      "HSI_AF7            0\n",
      "HSI_AF8            0\n",
      "HSI_TP10           0\n",
      "Battery            0\n",
      "SourceFile         0\n",
      "dtype: int64\n",
      "2025-03-14 09:29:01,760 - eeg_classification - INFO - Data spans 1436.02 seconds from 2024-06-23 03:40:25.403000 to 2024-06-23 04:04:21.418000\n",
      "2025-03-14 09:29:01,760 - eeg_classification - INFO - Data spans 1436.02 seconds from 2024-06-23 03:40:25.403000 to 2024-06-23 04:04:21.418000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:01,760 - eeg_classification - INFO - Data spans 1436.02 seconds from 2024-06-23 03:40:25.403000 to 2024-06-23 04:04:21.418000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,369 - eeg_classification - INFO - Sampling complete: 367668 -> 14400 data points (3.9%)\n",
      "2025-03-14 09:29:02,369 - eeg_classification - INFO - Sampling complete: 367668 -> 14400 data points (3.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,369 - eeg_classification - INFO - Sampling complete: 367668 -> 14400 data points (3.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,387 - eeg_classification - INFO - Preprocessing complete. Output shape: (14400, 41)\n",
      "2025-03-14 09:29:02,387 - eeg_classification - INFO - Preprocessing complete. Output shape: (14400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,387 - eeg_classification - INFO - Preprocessing complete. Output shape: (14400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,389 - eeg_classification - INFO - Cleaned data shape: (14400, 41)\n",
      "2025-03-14 09:29:02,389 - eeg_classification - INFO - Cleaned data shape: (14400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,389 - eeg_classification - INFO - Cleaned data shape: (14400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,391 - eeg_classification - INFO - Engineering features from data with shape (14400, 41)\n",
      "2025-03-14 09:29:02,391 - eeg_classification - INFO - Engineering features from data with shape (14400, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,391 - eeg_classification - INFO - Engineering features from data with shape (14400, 41)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,937 - eeg_classification - INFO - Feature engineering complete. Output shape: (14400, 140)\n",
      "2025-03-14 09:29:02,937 - eeg_classification - INFO - Feature engineering complete. Output shape: (14400, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:155: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_std\"] = df[col].rolling(window=window_size, center=True).std()\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\preprocessing.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_features[f\"{col}_range\"] = (\n",
      "2025-03-14 09:29:02,937 - eeg_classification - INFO - Feature engineering complete. Output shape: (14400, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,940 - eeg_classification - INFO - Features shape: (14400, 140)\n",
      "2025-03-14 09:29:02,940 - eeg_classification - INFO - Features shape: (14400, 140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,940 - eeg_classification - INFO - Features shape: (14400, 140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,952 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n",
      "2025-03-14 09:29:02,952 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,952 - eeg_classification - INFO - No. of missing values after feature engineering: TimeStamp         0\n",
      "Delta_TP9         0\n",
      "Delta_AF7         0\n",
      "Delta_AF8         0\n",
      "Delta_TP10        0\n",
      "                 ..\n",
      "HSI_TP10_std      0\n",
      "HSI_TP10_range    0\n",
      "Battery_mean      0\n",
      "Battery_std       0\n",
      "Battery_range     0\n",
      "Length: 140, dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,954 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n",
      "2025-03-14 09:29:02,954 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:02,954 - eeg_classification - INFO - Columns after feature engineering: Index(['TimeStamp', 'Delta_TP9', 'Delta_AF7', 'Delta_AF8', 'Delta_TP10',\n",
      "       'Theta_TP9', 'Theta_AF7', 'Theta_AF8', 'Theta_TP10', 'Alpha_TP9',\n",
      "       ...\n",
      "       'HSI_AF7_range', 'HSI_AF8_mean', 'HSI_AF8_std', 'HSI_AF8_range',\n",
      "       'HSI_TP10_mean', 'HSI_TP10_std', 'HSI_TP10_range', 'Battery_mean',\n",
      "       'Battery_std', 'Battery_range'],\n",
      "      dtype='object', length=140)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,126 - eeg_classification - INFO - Step 2 completed in 38.15 seconds\n",
      "2025-03-14 09:29:03,126 - eeg_classification - INFO - Step 2 completed in 38.15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,126 - eeg_classification - INFO - Step 2 completed in 38.15 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,129 - eeg_classification - INFO - \n",
      "================================================================================\n",
      "2025-03-14 09:29:03,129 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,129 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,131 - eeg_classification - INFO -  Step 3: Creating time series bundles on disk\n",
      "2025-03-14 09:29:03,131 - eeg_classification - INFO -  Step 3: Creating time series bundles on disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,131 - eeg_classification - INFO -  Step 3: Creating time series bundles on disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,135 - eeg_classification - INFO - ================================================================================\n",
      "2025-03-14 09:29:03,135 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,135 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,137 - eeg_classification - INFO - Bundle creation configuration:\n",
      "2025-03-14 09:29:03,137 - eeg_classification - INFO - Bundle creation configuration:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,137 - eeg_classification - INFO - Bundle creation configuration:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,139 - eeg_classification - INFO -   bundle_size: 30\n",
      "2025-03-14 09:29:03,139 - eeg_classification - INFO -   bundle_size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,139 - eeg_classification - INFO -   bundle_size: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,141 - eeg_classification - INFO -   step_size: 30\n",
      "2025-03-14 09:29:03,141 - eeg_classification - INFO -   step_size: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,141 - eeg_classification - INFO -   step_size: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,143 - eeg_classification - INFO -   max_files_per_batch: 2\n",
      "2025-03-14 09:29:03,143 - eeg_classification - INFO -   max_files_per_batch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,143 - eeg_classification - INFO -   max_files_per_batch: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,146 - eeg_classification - INFO -   max_bundles_per_file: 1000\n",
      "2025-03-14 09:29:03,146 - eeg_classification - INFO -   max_bundles_per_file: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,146 - eeg_classification - INFO -   max_bundles_per_file: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,148 - eeg_classification - INFO -   chunk_size: 1000\n",
      "2025-03-14 09:29:03,148 - eeg_classification - INFO -   chunk_size: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,148 - eeg_classification - INFO -   chunk_size: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,150 - eeg_classification - INFO -   output_dir: ./eeg_bundles\\bundles\n",
      "2025-03-14 09:29:03,150 - eeg_classification - INFO -   output_dir: ./eeg_bundles\\bundles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,150 - eeg_classification - INFO -   output_dir: ./eeg_bundles\\bundles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,152 - eeg_classification - INFO - Creating time series bundles with timestamp-based sampling...\n",
      "2025-03-14 09:29:03,152 - eeg_classification - INFO - Creating time series bundles with timestamp-based sampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,152 - eeg_classification - INFO - Creating time series bundles with timestamp-based sampling...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,155 - eeg_classification - INFO - Creating time series bundles and saving to disk\n",
      "2025-03-14 09:29:03,155 - eeg_classification - INFO - Creating time series bundles and saving to disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,155 - eeg_classification - INFO - Creating time series bundles and saving to disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,647 - eeg_classification - INFO - Processing files 1-2 of 30\n",
      "2025-03-14 09:29:03,647 - eeg_classification - INFO - Processing files 1-2 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,647 - eeg_classification - INFO - Processing files 1-2 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,665 - eeg_classification - INFO - Creating 141 bundles from file_1 with 4250 samples\n",
      "2025-03-14 09:29:03,665 - eeg_classification - INFO - Creating 141 bundles from file_1 with 4250 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,665 - eeg_classification - INFO - Creating 141 bundles from file_1 with 4250 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,981 - eeg_classification - INFO - Creating 100 bundles from file_2 with 3000 samples\n",
      "2025-03-14 09:29:03,981 - eeg_classification - INFO - Creating 100 bundles from file_2 with 3000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:03,981 - eeg_classification - INFO - Creating 100 bundles from file_2 with 3000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:04,223 - eeg_classification - INFO - Processing files 3-4 of 30\n",
      "2025-03-14 09:29:04,223 - eeg_classification - INFO - Processing files 3-4 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:04,223 - eeg_classification - INFO - Processing files 3-4 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:04,241 - eeg_classification - INFO - Creating 168 bundles from file_3 with 5050 samples\n",
      "2025-03-14 09:29:04,241 - eeg_classification - INFO - Creating 168 bundles from file_3 with 5050 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:04,241 - eeg_classification - INFO - Creating 168 bundles from file_3 with 5050 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:04,584 - eeg_classification - INFO - Creating 402 bundles from file_4 with 12082 samples\n",
      "2025-03-14 09:29:04,584 - eeg_classification - INFO - Creating 402 bundles from file_4 with 12082 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:04,584 - eeg_classification - INFO - Creating 402 bundles from file_4 with 12082 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:05,088 - eeg_classification - INFO - Processing files 5-6 of 30\n",
      "2025-03-14 09:29:05,088 - eeg_classification - INFO - Processing files 5-6 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:05,088 - eeg_classification - INFO - Processing files 5-6 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:05,120 - eeg_classification - INFO - Creating 380 bundles from file_5 with 11400 samples\n",
      "2025-03-14 09:29:05,120 - eeg_classification - INFO - Creating 380 bundles from file_5 with 11400 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:05,120 - eeg_classification - INFO - Creating 380 bundles from file_5 with 11400 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:05,727 - eeg_classification - INFO - Creating 380 bundles from file_6 with 11400 samples\n",
      "2025-03-14 09:29:05,727 - eeg_classification - INFO - Creating 380 bundles from file_6 with 11400 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:05,727 - eeg_classification - INFO - Creating 380 bundles from file_6 with 11400 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:06,301 - eeg_classification - INFO - Processing files 7-8 of 30\n",
      "2025-03-14 09:29:06,301 - eeg_classification - INFO - Processing files 7-8 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:06,301 - eeg_classification - INFO - Processing files 7-8 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:06,329 - eeg_classification - INFO - Creating 276 bundles from file_7 with 8300 samples\n",
      "2025-03-14 09:29:06,329 - eeg_classification - INFO - Creating 276 bundles from file_7 with 8300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:06,329 - eeg_classification - INFO - Creating 276 bundles from file_7 with 8300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:06,829 - eeg_classification - INFO - Creating 376 bundles from file_8 with 11300 samples\n",
      "2025-03-14 09:29:06,829 - eeg_classification - INFO - Creating 376 bundles from file_8 with 11300 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:06,829 - eeg_classification - INFO - Creating 376 bundles from file_8 with 11300 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:07,381 - eeg_classification - INFO - Processing files 9-10 of 30\n",
      "2025-03-14 09:29:07,381 - eeg_classification - INFO - Processing files 9-10 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:07,381 - eeg_classification - INFO - Processing files 9-10 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:07,407 - eeg_classification - INFO - Creating 275 bundles from file_9 with 8250 samples\n",
      "2025-03-14 09:29:07,407 - eeg_classification - INFO - Creating 275 bundles from file_9 with 8250 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:07,407 - eeg_classification - INFO - Creating 275 bundles from file_9 with 8250 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:07,914 - eeg_classification - INFO - Creating 553 bundles from file_10 with 16600 samples\n",
      "2025-03-14 09:29:07,914 - eeg_classification - INFO - Creating 553 bundles from file_10 with 16600 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:07,914 - eeg_classification - INFO - Creating 553 bundles from file_10 with 16600 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:08,615 - eeg_classification - INFO - Processing files 11-12 of 30\n",
      "2025-03-14 09:29:08,615 - eeg_classification - INFO - Processing files 11-12 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:08,615 - eeg_classification - INFO - Processing files 11-12 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:08,663 - eeg_classification - INFO - Creating 720 bundles from file_11 with 21600 samples\n",
      "2025-03-14 09:29:08,663 - eeg_classification - INFO - Creating 720 bundles from file_11 with 21600 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:08,663 - eeg_classification - INFO - Creating 720 bundles from file_11 with 21600 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:09,585 - eeg_classification - INFO - Creating 470 bundles from file_12 with 14100 samples\n",
      "2025-03-14 09:29:09,585 - eeg_classification - INFO - Creating 470 bundles from file_12 with 14100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:09,585 - eeg_classification - INFO - Creating 470 bundles from file_12 with 14100 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:10,264 - eeg_classification - INFO - Processing files 13-14 of 30\n",
      "2025-03-14 09:29:10,264 - eeg_classification - INFO - Processing files 13-14 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:10,264 - eeg_classification - INFO - Processing files 13-14 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:10,303 - eeg_classification - INFO - Creating 441 bundles from file_13 with 13250 samples\n",
      "2025-03-14 09:29:10,303 - eeg_classification - INFO - Creating 441 bundles from file_13 with 13250 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:10,303 - eeg_classification - INFO - Creating 441 bundles from file_13 with 13250 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:10,974 - eeg_classification - INFO - Creating 575 bundles from file_14 with 17250 samples\n",
      "2025-03-14 09:29:10,974 - eeg_classification - INFO - Creating 575 bundles from file_14 with 17250 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:10,974 - eeg_classification - INFO - Creating 575 bundles from file_14 with 17250 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:11,664 - eeg_classification - INFO - Processing files 15-16 of 30\n",
      "2025-03-14 09:29:11,664 - eeg_classification - INFO - Processing files 15-16 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:11,664 - eeg_classification - INFO - Processing files 15-16 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:11,692 - eeg_classification - INFO - Creating 325 bundles from file_15 with 9750 samples\n",
      "2025-03-14 09:29:11,692 - eeg_classification - INFO - Creating 325 bundles from file_15 with 9750 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:11,692 - eeg_classification - INFO - Creating 325 bundles from file_15 with 9750 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,267 - eeg_classification - INFO - Creating 103 bundles from file_16 with 3100 samples\n",
      "2025-03-14 09:29:12,267 - eeg_classification - INFO - Creating 103 bundles from file_16 with 3100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,267 - eeg_classification - INFO - Creating 103 bundles from file_16 with 3100 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,545 - eeg_classification - INFO - Processing files 17-18 of 30\n",
      "2025-03-14 09:29:12,545 - eeg_classification - INFO - Processing files 17-18 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,545 - eeg_classification - INFO - Processing files 17-18 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,559 - eeg_classification - INFO - Creating 111 bundles from file_17 with 3350 samples\n",
      "2025-03-14 09:29:12,559 - eeg_classification - INFO - Creating 111 bundles from file_17 with 3350 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,559 - eeg_classification - INFO - Creating 111 bundles from file_17 with 3350 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,824 - eeg_classification - INFO - Creating 225 bundles from file_18 with 6750 samples\n",
      "2025-03-14 09:29:12,824 - eeg_classification - INFO - Creating 225 bundles from file_18 with 6750 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:12,824 - eeg_classification - INFO - Creating 225 bundles from file_18 with 6750 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,152 - eeg_classification - INFO - Processing files 19-20 of 30\n",
      "2025-03-14 09:29:13,152 - eeg_classification - INFO - Processing files 19-20 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,152 - eeg_classification - INFO - Processing files 19-20 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,174 - eeg_classification - INFO - Creating 266 bundles from file_19 with 8000 samples\n",
      "2025-03-14 09:29:13,174 - eeg_classification - INFO - Creating 266 bundles from file_19 with 8000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,174 - eeg_classification - INFO - Creating 266 bundles from file_19 with 8000 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,563 - eeg_classification - INFO - Creating 116 bundles from file_20 with 3500 samples\n",
      "2025-03-14 09:29:13,563 - eeg_classification - INFO - Creating 116 bundles from file_20 with 3500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,563 - eeg_classification - INFO - Creating 116 bundles from file_20 with 3500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,806 - eeg_classification - INFO - Processing files 21-22 of 30\n",
      "2025-03-14 09:29:13,806 - eeg_classification - INFO - Processing files 21-22 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,806 - eeg_classification - INFO - Processing files 21-22 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,824 - eeg_classification - INFO - Creating 183 bundles from file_21 with 5500 samples\n",
      "2025-03-14 09:29:13,824 - eeg_classification - INFO - Creating 183 bundles from file_21 with 5500 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:13,824 - eeg_classification - INFO - Creating 183 bundles from file_21 with 5500 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:14,144 - eeg_classification - INFO - Creating 169 bundles from file_22 with 5094 samples\n",
      "2025-03-14 09:29:14,144 - eeg_classification - INFO - Creating 169 bundles from file_22 with 5094 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:14,144 - eeg_classification - INFO - Creating 169 bundles from file_22 with 5094 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:14,485 - eeg_classification - INFO - Processing files 23-24 of 30\n",
      "2025-03-14 09:29:14,485 - eeg_classification - INFO - Processing files 23-24 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:14,485 - eeg_classification - INFO - Processing files 23-24 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:14,517 - eeg_classification - INFO - Creating 338 bundles from file_23 with 10150 samples\n",
      "2025-03-14 09:29:14,517 - eeg_classification - INFO - Creating 338 bundles from file_23 with 10150 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:14,517 - eeg_classification - INFO - Creating 338 bundles from file_23 with 10150 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:15,017 - eeg_classification - INFO - Creating 306 bundles from file_24 with 9200 samples\n",
      "2025-03-14 09:29:15,017 - eeg_classification - INFO - Creating 306 bundles from file_24 with 9200 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:15,017 - eeg_classification - INFO - Creating 306 bundles from file_24 with 9200 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:15,479 - eeg_classification - INFO - Processing files 25-26 of 30\n",
      "2025-03-14 09:29:15,479 - eeg_classification - INFO - Processing files 25-26 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:15,479 - eeg_classification - INFO - Processing files 25-26 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:15,515 - eeg_classification - INFO - Creating 561 bundles from file_25 with 16850 samples\n",
      "2025-03-14 09:29:15,515 - eeg_classification - INFO - Creating 561 bundles from file_25 with 16850 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:15,515 - eeg_classification - INFO - Creating 561 bundles from file_25 with 16850 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,143 - eeg_classification - INFO - Creating 170 bundles from file_26 with 5100 samples\n",
      "2025-03-14 09:29:16,143 - eeg_classification - INFO - Creating 170 bundles from file_26 with 5100 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,143 - eeg_classification - INFO - Creating 170 bundles from file_26 with 5100 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,483 - eeg_classification - INFO - Processing files 27-28 of 30\n",
      "2025-03-14 09:29:16,483 - eeg_classification - INFO - Processing files 27-28 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,483 - eeg_classification - INFO - Processing files 27-28 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,499 - eeg_classification - INFO - Creating 153 bundles from file_27 with 4600 samples\n",
      "2025-03-14 09:29:16,499 - eeg_classification - INFO - Creating 153 bundles from file_27 with 4600 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,499 - eeg_classification - INFO - Creating 153 bundles from file_27 with 4600 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,797 - eeg_classification - INFO - Creating 131 bundles from file_28 with 3950 samples\n",
      "2025-03-14 09:29:16,797 - eeg_classification - INFO - Creating 131 bundles from file_28 with 3950 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:16,797 - eeg_classification - INFO - Creating 131 bundles from file_28 with 3950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:17,047 - eeg_classification - INFO - Processing files 29-30 of 30\n",
      "2025-03-14 09:29:17,047 - eeg_classification - INFO - Processing files 29-30 of 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:17,047 - eeg_classification - INFO - Processing files 29-30 of 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:17,065 - eeg_classification - INFO - Creating 165 bundles from file_29 with 4950 samples\n",
      "2025-03-14 09:29:17,065 - eeg_classification - INFO - Creating 165 bundles from file_29 with 4950 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:17,065 - eeg_classification - INFO - Creating 165 bundles from file_29 with 4950 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:17,411 - eeg_classification - INFO - Creating 480 bundles from file_30 with 14400 samples\n",
      "2025-03-14 09:29:17,411 - eeg_classification - INFO - Creating 480 bundles from file_30 with 14400 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:17,411 - eeg_classification - INFO - Creating 480 bundles from file_30 with 14400 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,247 - eeg_classification - INFO - Created 9059 total bundles on disk\n",
      "2025-03-14 09:29:18,247 - eeg_classification - INFO - Created 9059 total bundles on disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,247 - eeg_classification - INFO - Created 9059 total bundles on disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,269 - eeg_classification - INFO - Created 9059 bundles on disk\n",
      "2025-03-14 09:29:18,269 - eeg_classification - INFO - Created 9059 bundles on disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,269 - eeg_classification - INFO - Created 9059 bundles on disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,271 - eeg_classification - INFO - Bundle size: 30 time steps\n",
      "2025-03-14 09:29:18,271 - eeg_classification - INFO - Bundle size: 30 time steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,271 - eeg_classification - INFO - Bundle size: 30 time steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,273 - eeg_classification - INFO - Feature dimension: 138 features\n",
      "2025-03-14 09:29:18,273 - eeg_classification - INFO - Feature dimension: 138 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,273 - eeg_classification - INFO - Feature dimension: 138 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,275 - eeg_classification - INFO - Bundles saved to: ./eeg_bundles\\bundles\n",
      "2025-03-14 09:29:18,275 - eeg_classification - INFO - Bundles saved to: ./eeg_bundles\\bundles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,275 - eeg_classification - INFO - Bundles saved to: ./eeg_bundles\\bundles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,407 - eeg_classification - INFO - Saved bundle metadata to ./eeg_bundles\\bundle_metadata.csv\n",
      "2025-03-14 09:29:18,407 - eeg_classification - INFO - Saved bundle metadata to ./eeg_bundles\\bundle_metadata.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,407 - eeg_classification - INFO - Saved bundle metadata to ./eeg_bundles\\bundle_metadata.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,625 - eeg_classification - INFO - Step 3 completed in 15.49 seconds\n",
      "2025-03-14 09:29:18,625 - eeg_classification - INFO - Step 3 completed in 15.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,625 - eeg_classification - INFO - Step 3 completed in 15.49 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,627 - eeg_classification - INFO - \n",
      "================================================================================\n",
      "2025-03-14 09:29:18,627 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,627 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,629 - eeg_classification - INFO -  Step 4: Normalizing bundles on disk\n",
      "2025-03-14 09:29:18,629 - eeg_classification - INFO -  Step 4: Normalizing bundles on disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,629 - eeg_classification - INFO -  Step 4: Normalizing bundles on disk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,631 - eeg_classification - INFO - ================================================================================\n",
      "2025-03-14 09:29:18,631 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,631 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,633 - eeg_classification - INFO - Normalizing bundles...\n",
      "2025-03-14 09:29:18,633 - eeg_classification - INFO - Normalizing bundles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,633 - eeg_classification - INFO - Normalizing bundles...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,636 - eeg_classification - INFO - Normalizing bundles on disk with method: per_feature\n",
      "2025-03-14 09:29:18,636 - eeg_classification - INFO - Normalizing bundles on disk with method: per_feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,636 - eeg_classification - INFO - Normalizing bundles on disk with method: per_feature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,670 - eeg_classification - INFO - Computing feature means (pass 1/2)\n",
      "2025-03-14 09:29:18,670 - eeg_classification - INFO - Computing feature means (pass 1/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,670 - eeg_classification - INFO - Computing feature means (pass 1/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,672 - eeg_classification - INFO - Processing bundle 1/9059\n",
      "2025-03-14 09:29:18,672 - eeg_classification - INFO - Processing bundle 1/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:18,672 - eeg_classification - INFO - Processing bundle 1/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:27,098 - eeg_classification - INFO - Processing bundle 1001/9059\n",
      "2025-03-14 09:29:27,098 - eeg_classification - INFO - Processing bundle 1001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:27,098 - eeg_classification - INFO - Processing bundle 1001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:35,563 - eeg_classification - INFO - Processing bundle 2001/9059\n",
      "2025-03-14 09:29:35,563 - eeg_classification - INFO - Processing bundle 2001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:35,563 - eeg_classification - INFO - Processing bundle 2001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:43,572 - eeg_classification - INFO - Processing bundle 3001/9059\n",
      "2025-03-14 09:29:43,572 - eeg_classification - INFO - Processing bundle 3001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:43,572 - eeg_classification - INFO - Processing bundle 3001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:51,130 - eeg_classification - INFO - Processing bundle 4001/9059\n",
      "2025-03-14 09:29:51,130 - eeg_classification - INFO - Processing bundle 4001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:51,130 - eeg_classification - INFO - Processing bundle 4001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:59,894 - eeg_classification - INFO - Processing bundle 5001/9059\n",
      "2025-03-14 09:29:59,894 - eeg_classification - INFO - Processing bundle 5001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:29:59,894 - eeg_classification - INFO - Processing bundle 5001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:09,771 - eeg_classification - INFO - Processing bundle 6001/9059\n",
      "2025-03-14 09:30:09,771 - eeg_classification - INFO - Processing bundle 6001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:09,771 - eeg_classification - INFO - Processing bundle 6001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:17,295 - eeg_classification - INFO - Processing bundle 7001/9059\n",
      "2025-03-14 09:30:17,295 - eeg_classification - INFO - Processing bundle 7001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:17,295 - eeg_classification - INFO - Processing bundle 7001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:24,953 - eeg_classification - INFO - Processing bundle 8001/9059\n",
      "2025-03-14 09:30:24,953 - eeg_classification - INFO - Processing bundle 8001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:24,953 - eeg_classification - INFO - Processing bundle 8001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,334 - eeg_classification - INFO - Processing bundle 9001/9059\n",
      "2025-03-14 09:30:32,334 - eeg_classification - INFO - Processing bundle 9001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,334 - eeg_classification - INFO - Processing bundle 9001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,842 - eeg_classification - INFO - Processing bundle 9059/9059\n",
      "2025-03-14 09:30:32,842 - eeg_classification - INFO - Processing bundle 9059/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,842 - eeg_classification - INFO - Processing bundle 9059/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,851 - eeg_classification - INFO - Normalizing bundles (pass 2/2)\n",
      "2025-03-14 09:30:32,851 - eeg_classification - INFO - Normalizing bundles (pass 2/2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\bundles.py:650: RuntimeWarning: invalid value encountered in subtract\n",
      "  feature_vars = (feature_sq_sums / total_samples) - (feature_means**2)\n",
      "2025-03-14 09:30:32,851 - eeg_classification - INFO - Normalizing bundles (pass 2/2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,853 - eeg_classification - INFO - Normalizing bundle 1/9059\n",
      "2025-03-14 09:30:32,853 - eeg_classification - INFO - Normalizing bundle 1/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:32,853 - eeg_classification - INFO - Normalizing bundle 1/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:33,929 - eeg_classification - INFO - Normalizing bundle 1001/9059\n",
      "2025-03-14 09:30:33,929 - eeg_classification - INFO - Normalizing bundle 1001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:33,929 - eeg_classification - INFO - Normalizing bundle 1001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:35,040 - eeg_classification - INFO - Normalizing bundle 2001/9059\n",
      "2025-03-14 09:30:35,040 - eeg_classification - INFO - Normalizing bundle 2001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:35,040 - eeg_classification - INFO - Normalizing bundle 2001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:36,361 - eeg_classification - INFO - Normalizing bundle 3001/9059\n",
      "2025-03-14 09:30:36,361 - eeg_classification - INFO - Normalizing bundle 3001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:36,361 - eeg_classification - INFO - Normalizing bundle 3001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:37,717 - eeg_classification - INFO - Normalizing bundle 4001/9059\n",
      "2025-03-14 09:30:37,717 - eeg_classification - INFO - Normalizing bundle 4001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:37,717 - eeg_classification - INFO - Normalizing bundle 4001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:39,123 - eeg_classification - INFO - Normalizing bundle 5001/9059\n",
      "2025-03-14 09:30:39,123 - eeg_classification - INFO - Normalizing bundle 5001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:39,123 - eeg_classification - INFO - Normalizing bundle 5001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:40,429 - eeg_classification - INFO - Normalizing bundle 6001/9059\n",
      "2025-03-14 09:30:40,429 - eeg_classification - INFO - Normalizing bundle 6001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:40,429 - eeg_classification - INFO - Normalizing bundle 6001/9059\n",
      "c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\bundles.py:667: RuntimeWarning: invalid value encountered in subtract\n",
      "  normalized_bundle = (bundle - feature_means) / feature_stds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:41,784 - eeg_classification - INFO - Normalizing bundle 7001/9059\n",
      "2025-03-14 09:30:41,784 - eeg_classification - INFO - Normalizing bundle 7001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:41,784 - eeg_classification - INFO - Normalizing bundle 7001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:43,162 - eeg_classification - INFO - Normalizing bundle 8001/9059\n",
      "2025-03-14 09:30:43,162 - eeg_classification - INFO - Normalizing bundle 8001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:43,162 - eeg_classification - INFO - Normalizing bundle 8001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,576 - eeg_classification - INFO - Normalizing bundle 9001/9059\n",
      "2025-03-14 09:30:44,576 - eeg_classification - INFO - Normalizing bundle 9001/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,576 - eeg_classification - INFO - Normalizing bundle 9001/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,814 - eeg_classification - INFO - Normalizing bundle 9059/9059\n",
      "2025-03-14 09:30:44,814 - eeg_classification - INFO - Normalizing bundle 9059/9059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,814 - eeg_classification - INFO - Normalizing bundle 9059/9059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,819 - eeg_classification - INFO - Bundle normalization complete\n",
      "2025-03-14 09:30:44,819 - eeg_classification - INFO - Bundle normalization complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,819 - eeg_classification - INFO - Bundle normalization complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,823 - eeg_classification - INFO - Normalized bundles using per_feature method\n",
      "2025-03-14 09:30:44,823 - eeg_classification - INFO - Normalized bundles using per_feature method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,823 - eeg_classification - INFO - Normalized bundles using per_feature method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,825 - eeg_classification - INFO - Normalization parameters saved to ./eeg_bundles\\bundles\\normalization_params.joblib\n",
      "2025-03-14 09:30:44,825 - eeg_classification - INFO - Normalization parameters saved to ./eeg_bundles\\bundles\\normalization_params.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,825 - eeg_classification - INFO - Normalization parameters saved to ./eeg_bundles\\bundles\\normalization_params.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,827 - eeg_classification - INFO - Step 4 completed in 86.19 seconds\n",
      "2025-03-14 09:30:44,827 - eeg_classification - INFO - Step 4 completed in 86.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:30:44,827 - eeg_classification - INFO - Step 4 completed in 86.19 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if we should load existing bundles\n",
    "bundle_info = None\n",
    "if load_existing:\n",
    "    try:\n",
    "        logger.info(\"Checking for existing bundles...\")\n",
    "        bundle_info = load_bundle_info(bundle_dir)\n",
    "        logger.info(f\"Found existing bundles: {bundle_info['total_bundles']} bundles with shape \" \n",
    "                    f\"({bundle_info['bundle_size']}, {bundle_info['feature_dim']})\")\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        logger.warning(f\"Could not load existing bundles: {str(e)}\")\n",
    "        bundle_info = None\n",
    "\n",
    "# If we don't have existing bundles, create them\n",
    "if bundle_info is None:\n",
    "    #---------------------------------------------------------------------------\n",
    "    # Step 1: Load Data\n",
    "    #---------------------------------------------------------------------------\n",
    "    print_section_header(\"Step 1: Loading EEG data\")\n",
    "    step_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        logger.info(f\"Loading data from {data_dir}\")\n",
    "        file_dfs, combined_df = load_eeg_data(directory_path=data_dir)\n",
    "        \n",
    "        n_files = len(file_dfs)\n",
    "        total_rows = sum(len(df) for df in file_dfs.values())\n",
    "        logger.info(f\"Loaded {n_files} files with {total_rows} total rows\")\n",
    "        \n",
    "        # Get first file for visualization\n",
    "        sample_file_id = list(file_dfs.keys())[0]\n",
    "        sample_df = file_dfs[sample_file_id]\n",
    "        logger.info(f\"Sample file {sample_file_id} shape: {sample_df.shape}\")\n",
    "        \n",
    "        # Visualize raw data\n",
    "        fig = visualize_eeg_data(sample_df, max_cols=5)\n",
    "        save_plot(fig, \"raw_eeg_data.png\", dirs[\"plots\"])\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading data: {str(e)}\")\n",
    "        logger.exception(\"Stack trace:\")\n",
    "        \n",
    "    \n",
    "    logger.info(f\"Step 1 completed in {time.time() - step_start:.2f} seconds\")\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Step 2: Preprocess Data and Engineer Features\n",
    "    #---------------------------------------------------------------------------\n",
    "    print_section_header(\"Step 2: Processing data and engineering features\")\n",
    "    step_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Analyze NaN patterns in the sample file first\n",
    "        logger.info(f\"Analyzing data quality for sample file {sample_file_id}\")\n",
    "        sample_quality = analyze_data_quality(sample_df)\n",
    "        \n",
    "        # Save the plot if it exists\n",
    "        if 'plot' in sample_quality and sample_quality['plot'] is not None:\n",
    "            save_plot(sample_quality['plot'], \"sample_data_quality.png\", dirs[\"plots\"])\n",
    "\n",
    "        # Save high NaN columns for later use\n",
    "        high_nan_cols = sample_quality.get('high_nan_columns', [])\n",
    "        logger.info(f\"Saved list of {high_nan_cols} high-NaN columns for reference\")\n",
    "        \n",
    "\n",
    "        processed_dfs = {}\n",
    "        \n",
    "        for file_id, df in file_dfs.items():\n",
    "            logger.info(f\"Processing file {file_id} with {len(df)} rows\")\n",
    "            df = df.drop(columns=[\"Elements\"])\n",
    "            # Check for NaN values in input\n",
    "            nan_count_before = df.isna().sum().sum()\n",
    "            if nan_count_before > 0:\n",
    "                logger.warning(f\"Input data for file {file_id} contains {nan_count_before} NaN values\")\n",
    "            \n",
    "\n",
    "            # Clean data\n",
    "            clean_df = preprocess_eeg_data(df)\n",
    "            logger.info(f\"Cleaned data shape: {clean_df.shape}\")\n",
    "\n",
    "            # Engineer features\n",
    "            features_df = engineer_eeg_features(clean_df)\n",
    "            logger.info(f\"Features shape: {features_df.shape}\")\n",
    "            \n",
    "            logger.info(f\"No. of missing values after feature engineering: {features_df.isna().sum()}\")\n",
    "            logger.info(f\"Columns after feature engineering: {features_df.columns}\")\n",
    "            \n",
    "            # Store processed DataFrame\n",
    "            processed_dfs[file_id] = features_df\n",
    "            \n",
    "            # If this is the first file, visualize the processed data\n",
    "            if file_id == sample_file_id:\n",
    "                fig = visualize_eeg_data(features_df, max_cols=5)\n",
    "                save_plot(fig, \"processed_eeg_data.png\", dirs[\"plots\"])\n",
    "            \n",
    "            # Free memory\n",
    "            del clean_df\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data quality analysis: {str(e)}\")\n",
    "        logger.exception(\"Stack trace:\")\n",
    "        # Continue with pipeline despite analysis error\n",
    "    \n",
    "    logger.info(f\"Step 2 completed in {time.time() - step_start:.2f} seconds\")\n",
    "\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Step 3: Create Time Series Bundles on Disk\n",
    "    #---------------------------------------------------------------------------\n",
    "    print_section_header(\"Step 3: Creating time series bundles on disk\")\n",
    "    step_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Configuration for bundle creation\n",
    "        bundle_config = {\n",
    "            'bundle_size': bundle_size,         # Number of time steps per bundle\n",
    "            'step_size': step_size,             # Step size for sliding window\n",
    "            'max_files_per_batch': 2,                # Process 2 files at a time\n",
    "            'max_bundles_per_file': 1000,            # Maximum 1000 bundles per file\n",
    "            'chunk_size': 1000,                       # Process 500 bundles at a time\n",
    "            'output_dir': bundle_dir,                # Where to save bundles\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Bundle creation configuration:\")\n",
    "        for key, value in bundle_config.items():\n",
    "            logger.info(f\"  {key}: {value}\")\n",
    "        \n",
    "        # Create time series bundles and save to disk\n",
    "        logger.info(\"Creating time series bundles with timestamp-based sampling...\")\n",
    "        metadata_df, bundle_info = create_coherent_time_series_bundles_disk(\n",
    "            file_dfs=processed_dfs,\n",
    "            **bundle_config\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Created {bundle_info['total_bundles']} bundles on disk\")\n",
    "        logger.info(f\"Bundle size: {bundle_info['bundle_size']} time steps\")\n",
    "        logger.info(f\"Feature dimension: {bundle_info['feature_dim']} features\")\n",
    "        logger.info(f\"Bundles saved to: {bundle_info['output_dir']}\")\n",
    "        \n",
    "        # Save metadata to a more readable format\n",
    "        metadata_csv = os.path.join(dirs['base'], \"bundle_metadata.csv\")\n",
    "        metadata_df.to_csv(metadata_csv, index=False)\n",
    "        logger.info(f\"Saved bundle metadata to {metadata_csv}\")\n",
    "        \n",
    "        # Free memory\n",
    "        del processed_dfs\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating bundles: {str(e)}\")\n",
    "        logger.exception(\"Stack trace:\")\n",
    "        \n",
    "    \n",
    "    logger.info(f\"Step 3 completed in {time.time() - step_start:.2f} seconds\")\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Step 4: Normalize Bundles on Disk\n",
    "    #---------------------------------------------------------------------------\n",
    "    print_section_header(\"Step 4: Normalizing bundles on disk\")\n",
    "    step_start = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Normalize bundles\n",
    "        logger.info(\"Normalizing bundles...\")\n",
    "        bundle_info = normalize_bundles_disk(\n",
    "            bundle_info=bundle_info,\n",
    "            normalization='per_feature'  # Normalize each feature independently\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Normalized bundles using {bundle_info['normalization']} method\")\n",
    "        logger.info(f\"Normalization parameters saved to {bundle_info['normalization_params_path']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error normalizing bundles: {str(e)}\")\n",
    "        logger.exception(\"Stack trace:\")\n",
    "        \n",
    "    \n",
    "    logger.info(f\"Step 4 completed in {time.time() - step_start:.2f} seconds\")\n",
    "\n",
    "else:\n",
    "    # We loaded existing bundles, so let's load the metadata too\n",
    "    metadata_csv = os.path.join(dirs['base'], \"bundle_metadata.csv\")\n",
    "    if os.path.exists(metadata_csv):\n",
    "        metadata_df = pd.read_csv(metadata_csv)\n",
    "        logger.info(f\"Loaded existing metadata with {len(metadata_df)} rows\")\n",
    "    else:\n",
    "        # Try to find metadata in the bundle directory\n",
    "        metadata_path = os.path.join(bundle_dir, \"metadata.csv\")\n",
    "        if os.path.exists(metadata_path):\n",
    "            metadata_df = pd.read_csv(metadata_path)\n",
    "            logger.info(f\"Loaded metadata from bundle directory with {len(metadata_df)} rows\")\n",
    "        else:\n",
    "            # Try joblib format\n",
    "            metadata_path = os.path.join(bundle_dir, \"metadata.joblib\")\n",
    "            if os.path.exists(metadata_path):\n",
    "                metadata_df = joblib.load(metadata_path)\n",
    "                logger.info(f\"Loaded metadata from bundle directory with {len(metadata_df)} rows\")\n",
    "            else:\n",
    "                logger.error(\"Could not find metadata file\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,308 - eeg_classification - INFO - \n",
      "================================================================================\n",
      "2025-03-14 09:32:56,308 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,308 - eeg_classification - INFO - \n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,311 - eeg_classification - INFO -  Step 5: Performing unsupervised clustering\n",
      "2025-03-14 09:32:56,311 - eeg_classification - INFO -  Step 5: Performing unsupervised clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,311 - eeg_classification - INFO -  Step 5: Performing unsupervised clustering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,313 - eeg_classification - INFO - ================================================================================\n",
      "2025-03-14 09:32:56,313 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,313 - eeg_classification - INFO - ================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,318 - eeg_classification - INFO - Split 9059 bundles into 7247 for analysis and 1812 for evaluation\n",
      "2025-03-14 09:32:56,318 - eeg_classification - INFO - Split 9059 bundles into 7247 for analysis and 1812 for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,318 - eeg_classification - INFO - Split 9059 bundles into 7247 for analysis and 1812 for evaluation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,321 - eeg_classification - INFO - Initialized UnsupervisedModelTrainer with model_type=kmeans\n",
      "2025-03-14 09:32:56,321 - eeg_classification - INFO - Initialized UnsupervisedModelTrainer with model_type=kmeans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,321 - eeg_classification - INFO - Initialized UnsupervisedModelTrainer with model_type=kmeans\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,323 - eeg_classification - INFO - Using 1000 samples to determine optimal number of clusters\n",
      "2025-03-14 09:32:56,323 - eeg_classification - INFO - Using 1000 samples to determine optimal number of clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:32:56,323 - eeg_classification - INFO - Using 1000 samples to determine optimal number of clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,226 - eeg_classification - INFO - Sample data shape for clustering: (1000, 138)\n",
      "2025-03-14 09:33:04,226 - eeg_classification - INFO - Sample data shape for clustering: (1000, 138)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,226 - eeg_classification - INFO - Sample data shape for clustering: (1000, 138)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,230 - eeg_classification - INFO - Number of NaN values in sample data: 10000\n",
      "2025-03-14 09:33:04,230 - eeg_classification - INFO - Number of NaN values in sample data: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,230 - eeg_classification - INFO - Number of NaN values in sample data: 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,232 - eeg_classification - INFO - Finding optimal number of clusters between 2 and 5\n",
      "2025-03-14 09:33:04,232 - eeg_classification - INFO - Finding optimal number of clusters between 2 and 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,232 - eeg_classification - INFO - Finding optimal number of clusters between 2 and 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,235 - eeg_classification - ERROR - Error finding optimal clusters: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-03-14 09:33:04,235 - eeg_classification - ERROR - Error finding optimal clusters: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,235 - eeg_classification - ERROR - Error finding optimal clusters: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,245 - eeg_classification - ERROR - Error in unsupervised learning: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-03-14 09:33:04,245 - eeg_classification - ERROR - Error in unsupervised learning: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,245 - eeg_classification - ERROR - Error in unsupervised learning: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,248 - eeg_classification - ERROR - Stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Huai\\AppData\\Local\\Temp\\ipykernel_32816\\847493052.py\", line 66, in <module>\n",
      "    optimal_n, score = trainer.find_optimal_clusters(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\unsupervised.py\", line 192, in find_optimal_clusters\n",
      "    labels = kmeans.fit_predict(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1064, in fit_predict\n",
      "    return self.fit(X, sample_weight=sample_weight).labels_\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1454, in fit\n",
      "    X = validate_data(\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2944, in validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "2025-03-14 09:33:04,248 - eeg_classification - ERROR - Stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Huai\\AppData\\Local\\Temp\\ipykernel_32816\\847493052.py\", line 66, in <module>\n",
      "    optimal_n, score = trainer.find_optimal_clusters(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\unsupervised.py\", line 192, in find_optimal_clusters\n",
      "    labels = kmeans.fit_predict(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1064, in fit_predict\n",
      "    return self.fit(X, sample_weight=sample_weight).labels_\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1454, in fit\n",
      "    X = validate_data(\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2944, in validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,248 - eeg_classification - ERROR - Stack trace:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Huai\\AppData\\Local\\Temp\\ipykernel_32816\\847493052.py\", line 66, in <module>\n",
      "    optimal_n, score = trainer.find_optimal_clusters(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\Documents\\GitHub\\EEG-classification\\training\\common\\unsupervised.py\", line 192, in find_optimal_clusters\n",
      "    labels = kmeans.fit_predict(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1064, in fit_predict\n",
      "    return self.fit(X, sample_weight=sample_weight).labels_\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py\", line 1454, in fit\n",
      "    X = validate_data(\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2944, in validate_data\n",
      "    out = check_array(X, input_name=\"X\", **check_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1107, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 120, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"c:\\Users\\Huai\\miniconda3\\envs\\eeg\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 169, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input X contains NaN.\n",
      "KMeans does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,251 - eeg_classification - INFO - Step 5 completed in 7.94 seconds\n",
      "2025-03-14 09:33:04,251 - eeg_classification - INFO - Step 5 completed in 7.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 09:33:04,251 - eeg_classification - INFO - Step 5 completed in 7.94 seconds\n"
     ]
    }
   ],
   "source": [
    "n_clusters = None\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Step 5: Unsupervised Learning (Clustering)\n",
    "#---------------------------------------------------------------------------\n",
    "print_section_header(\"Step 5: Performing unsupervised clustering\")\n",
    "step_start = time.time()\n",
    "\n",
    "try:\n",
    "    # Create loader for the data\n",
    "    from common import DiskBundleLoader\n",
    "    \n",
    "    # For clustering, we need to create a batch loader\n",
    "    all_indices = np.arange(bundle_info['total_bundles'])\n",
    "    \n",
    "    # Split into analysis (80%) and evaluation (20%) sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    analysis_indices, evaluation_indices = train_test_split(\n",
    "        all_indices, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Split {len(all_indices)} bundles into {len(analysis_indices)} for analysis \" \n",
    "                f\"and {len(evaluation_indices)} for evaluation\")\n",
    "    \n",
    "    # Save indices for future reference\n",
    "    np.save(os.path.join(dirs['base'], 'analysis_indices.npy'), analysis_indices)\n",
    "    np.save(os.path.join(dirs['base'], 'evaluation_indices.npy'), evaluation_indices)\n",
    "    \n",
    "    # Initialize the clustering model\n",
    "    trainer = UnsupervisedModelTrainer(\n",
    "        model_type='kmeans',\n",
    "        random_state=42,\n",
    "        config={'n_clusters': n_clusters if n_clusters is not None else 2}  # Default to 2 if not specified\n",
    "    )\n",
    "    \n",
    "    # Get a sample for finding optimal number of clusters\n",
    "    sample_size = min(1000, len(analysis_indices))\n",
    "    sample_indices = np.random.choice(analysis_indices, sample_size, replace=False)\n",
    "    \n",
    "    logger.info(f\"Using {sample_size} samples to determine optimal number of clusters\")\n",
    "    \n",
    "    # Create loader for sample data\n",
    "    sample_loader = DiskBundleLoader(\n",
    "        bundle_info=bundle_info,\n",
    "        indices=sample_indices,\n",
    "        batch_size=sample_size,  # Load all in one batch\n",
    "        shuffle=False,\n",
    "        use_normalized=True\n",
    "    )\n",
    "    \n",
    "    # Load sample data for cluster optimization\n",
    "    sample_data = next(iter(sample_loader))\n",
    "    \n",
    "    # If data is 3D, flatten time dimension by taking mean\n",
    "    if sample_data.ndim == 3:\n",
    "        sample_data = sample_data.mean(axis=1)\n",
    "        \n",
    "    logger.info(f\"Sample data shape for clustering: {sample_data.shape}\")\n",
    "\n",
    "    # Count number of rows that are NaN\n",
    "    nan_count = np.isnan(sample_data).sum()\n",
    "    logger.info(f\"Number of NaN values in sample data: {nan_count}\")\n",
    "\n",
    "    # Find optimal number of clusters if not specified\n",
    "    if n_clusters is None:\n",
    "        optimal_n, score = trainer.find_optimal_clusters(\n",
    "            sample_data, min_clusters=2, max_clusters=5\n",
    "        )\n",
    "        logger.info(f\"Optimal number of clusters: {optimal_n} (score: {score:.4f})\")\n",
    "    else:\n",
    "        optimal_n = n_clusters\n",
    "        logger.info(f\"Using specified number of clusters: {optimal_n}\")\n",
    "        \n",
    "    # Set the optimal number of clusters in the trainer\n",
    "    trainer.create_model(n_clusters=optimal_n)\n",
    "    \n",
    "    # Process all analysis data in batches\n",
    "    logger.info(f\"Clustering {len(analysis_indices)} bundles...\")\n",
    "    \n",
    "    batch_size = 500  # Process 500 samples at a time\n",
    "    analysis_batches = [analysis_indices[i:i+batch_size] for i in range(0, len(analysis_indices), batch_size)]\n",
    "    \n",
    "    all_labels = []\n",
    "    all_data_for_vis = None  # For visualization\n",
    "    \n",
    "    for i, batch_indices in enumerate(analysis_batches):\n",
    "        # Create loader for this batch\n",
    "        batch_loader = DiskBundleLoader(\n",
    "            bundle_info=bundle_info,\n",
    "            indices=batch_indices,\n",
    "            batch_size=len(batch_indices),\n",
    "            shuffle=False,\n",
    "            use_normalized=True\n",
    "        )\n",
    "        \n",
    "        # Load batch\n",
    "        batch_data = next(iter(batch_loader))\n",
    "        \n",
    "        # If bundles are 3D, flatten the time dimension\n",
    "        if batch_data.ndim == 3:\n",
    "            batch_data = batch_data.mean(axis=1)\n",
    "        \n",
    "        # Store first batch for visualization\n",
    "        if i == 0 and all_data_for_vis is None:\n",
    "            # Keep only a subset for visualization to save memory\n",
    "            vis_size = min(500, len(batch_data))\n",
    "            all_data_for_vis = batch_data[:vis_size].copy()\n",
    "            \n",
    "        # Fit or predict with the model\n",
    "        if i == 0:\n",
    "            # First batch - fit the model\n",
    "            batch_labels = trainer.train(batch_data)\n",
    "            logger.info(\"Fitted clustering model on first batch\")\n",
    "        else:\n",
    "            # Subsequent batches - predict only\n",
    "            batch_labels = trainer.model.predict(batch_data)\n",
    "        \n",
    "        all_labels.append(batch_labels)\n",
    "        \n",
    "        logger.info(f\"  Processed batch {i+1}/{len(analysis_batches)} ({len(batch_indices)} bundles)\")\n",
    "        \n",
    "        # Free memory\n",
    "        del batch_data, batch_loader\n",
    "        gc.collect()\n",
    "    \n",
    "    # Combine all labels\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # Get cluster distribution\n",
    "    unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "    logger.info(\"Cluster distribution:\")\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        percentage = (count / len(all_labels)) * 100\n",
    "        logger.info(f\"  Cluster {label}: {count} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Visualize clusters using stored data subset\n",
    "    if all_data_for_vis is not None:\n",
    "        # Reduce dimensions for visualization\n",
    "        # Try t-SNE first, fall back to PCA if not available\n",
    "        try:\n",
    "            from sklearn.manifold import TSNE\n",
    "            logger.info(\"Using t-SNE for dimension reduction...\")\n",
    "            X_reduced = TSNE(n_components=2, random_state=42).fit_transform(all_data_for_vis)\n",
    "        except:\n",
    "            logger.info(\"Falling back to PCA for dimension reduction...\")\n",
    "            from sklearn.decomposition import PCA\n",
    "            X_reduced = PCA(n_components=2, random_state=42).fit_transform(all_data_for_vis)\n",
    "        \n",
    "        # Get corresponding labels\n",
    "        vis_labels = trainer.model.predict(all_data_for_vis)\n",
    "        \n",
    "        # Create scatter plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=vis_labels, cmap='viridis', alpha=0.7)\n",
    "        plt.colorbar(scatter, label='Cluster')\n",
    "        plt.title(f'EEG Data Clusters (n={optimal_n})')\n",
    "        plt.xlabel('Component 1')\n",
    "        plt.ylabel('Component 2')\n",
    "        plt.tight_layout()\n",
    "        save_plot(plt.gcf(), \"cluster_visualization.png\", dirs[\"plots\"])\n",
    "        \n",
    "        # Free memory\n",
    "        del all_data_for_vis\n",
    "        gc.collect()\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(dirs[\"models\"], \"unsupervised_model.joblib\")\n",
    "    trainer.save_model(model_path)\n",
    "    logger.info(f\"Saved clustering model to {model_path}\")\n",
    "    \n",
    "    # Add cluster labels to metadata\n",
    "    metadata_with_clusters = metadata_df.copy()\n",
    "    metadata_with_clusters['cluster'] = -1  # Initialize with -1 (unclustered)\n",
    "    \n",
    "    # Map indices to bundle_idx in metadata\n",
    "    for i, idx in enumerate(analysis_indices):\n",
    "        if i < len(all_labels):\n",
    "            metadata_with_clusters.loc[metadata_with_clusters['bundle_idx'] == idx, 'cluster'] = all_labels[i]\n",
    "    \n",
    "    # Save updated metadata\n",
    "    metadata_path = os.path.join(dirs[\"base\"], \"metadata_with_clusters.csv\")\n",
    "    metadata_with_clusters.to_csv(metadata_path, index=False)\n",
    "    logger.info(f\"Saved metadata with cluster labels to {metadata_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in unsupervised learning: {str(e)}\")\n",
    "    logger.exception(\"Stack trace:\")\n",
    "\n",
    "logger.info(f\"Step 5 completed in {time.time() - step_start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Step 6: Cluster Evaluation\n",
    "#---------------------------------------------------------------------------\n",
    "print_section_header(\"Step 6: Evaluating clustering results\")\n",
    "step_start = time.time()\n",
    "\n",
    "try:\n",
    "    # Evaluate on the held-out evaluation set\n",
    "    logger.info(f\"Evaluating clustering on {len(evaluation_indices)} held-out bundles\")\n",
    "    \n",
    "    # Process in batches\n",
    "    batch_size = 500\n",
    "    evaluation_batches = [evaluation_indices[i:i+batch_size] for i in range(0, len(evaluation_indices), batch_size)]\n",
    "    \n",
    "    eval_labels = []\n",
    "    \n",
    "    for i, batch_indices in enumerate(evaluation_batches):\n",
    "        # Create loader for this batch\n",
    "        batch_loader = DiskBundleLoader(\n",
    "            bundle_info=bundle_info,\n",
    "            indices=batch_indices,\n",
    "            batch_size=len(batch_indices),\n",
    "            shuffle=False,\n",
    "            use_normalized=True\n",
    "        )\n",
    "        \n",
    "        # Load batch\n",
    "        batch_data = next(iter(batch_loader))\n",
    "        \n",
    "        # If bundles are 3D, flatten the time dimension\n",
    "        if batch_data.ndim == 3:\n",
    "            batch_data = batch_data.mean(axis=1)\n",
    "            \n",
    "        # Predict clusters\n",
    "        batch_labels = trainer.model.predict(batch_data)\n",
    "        eval_labels.append(batch_labels)\n",
    "        \n",
    "        logger.info(f\"  Processed evaluation batch {i+1}/{len(evaluation_batches)} ({len(batch_indices)} bundles)\")\n",
    "        \n",
    "        # Free memory\n",
    "        del batch_data, batch_loader\n",
    "        gc.collect()\n",
    "    \n",
    "    # Combine all evaluation labels\n",
    "    eval_labels = np.concatenate(eval_labels)\n",
    "    \n",
    "    # Get cluster distribution\n",
    "    eval_unique_labels, eval_counts = np.unique(eval_labels, return_counts=True)\n",
    "    logger.info(\"Cluster distribution in evaluation data:\")\n",
    "    for label, count in zip(eval_unique_labels, eval_counts):\n",
    "        percentage = (count / len(eval_labels)) * 100\n",
    "        logger.info(f\"  Cluster {label}: {count} samples ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Compare distributions between analysis and evaluation sets\n",
    "    logger.info(\"Comparing cluster distributions:\")\n",
    "    logger.info(\"  Cluster  |  Analysis  |  Evaluation\")\n",
    "    logger.info(\"  --------|------------|------------\")\n",
    "    for label in range(optimal_n):\n",
    "        # Find index of this label in the analysis set\n",
    "        analysis_idx = np.where(unique_labels == label)[0]\n",
    "        analysis_count = counts[analysis_idx[0]] if len(analysis_idx) > 0 else 0\n",
    "        analysis_pct = (analysis_count / len(all_labels)) * 100 if len(all_labels) > 0 else 0\n",
    "        \n",
    "        # Find index of this label in the evaluation set\n",
    "        eval_idx = np.where(eval_unique_labels == label)[0]\n",
    "        eval_count = eval_counts[eval_idx[0]] if len(eval_idx) > 0 else 0\n",
    "        eval_pct = (eval_count / len(eval_labels)) * 100 if len(eval_labels) > 0 else 0\n",
    "        \n",
    "        logger.info(f\"  {label}       |  {analysis_pct:.1f}%     |  {eval_pct:.1f}%\")\n",
    "    \n",
    "    # Calculate silhouette scores if possible\n",
    "    try:\n",
    "        from sklearn.metrics import silhouette_score\n",
    "        \n",
    "        # We need a sample of data for silhouette calculation\n",
    "        # This might be memory intensive for large datasets\n",
    "        sample_size = min(10000, len(evaluation_indices))\n",
    "        sample_indices = np.random.choice(evaluation_indices, sample_size, replace=False)\n",
    "        \n",
    "        # Load the sample\n",
    "        sample_loader = DiskBundleLoader(\n",
    "            bundle_info=bundle_info,\n",
    "            indices=sample_indices,\n",
    "            batch_size=sample_size,\n",
    "            shuffle=False,\n",
    "            use_normalized=True\n",
    "        )\n",
    "        \n",
    "        # Get the data\n",
    "        sample_data = next(iter(sample_loader))\n",
    "        \n",
    "        # If 3D, flatten\n",
    "        if sample_data.ndim == 3:\n",
    "            sample_data = sample_data.mean(axis=1)\n",
    "        \n",
    "        # Predict labels\n",
    "        sample_labels = trainer.model.predict(sample_data)\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        sil_score = silhouette_score(sample_data, sample_labels)\n",
    "        logger.info(f\"Silhouette Score on evaluation data: {sil_score:.4f}\")\n",
    "        \n",
    "        # Add to summary dict\n",
    "        eval_scores = {\"silhouette_score\": sil_score}\n",
    "        \n",
    "        # Free memory\n",
    "        del sample_data, sample_loader\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.warning(f\"Could not calculate silhouette score: {str(e)}\")\n",
    "        eval_scores = {}\n",
    "    \n",
    "    # Calculate cluster evaluation metrics\n",
    "    metrics = trainer.evaluate(sample_data, sample_labels)\n",
    "    logger.info(\"Cluster evaluation metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        logger.info(f\"  {metric}: {value:.4f}\")\n",
    "        eval_scores[metric] = value\n",
    "    \n",
    "    # Save evaluation metrics\n",
    "    eval_path = os.path.join(dirs[\"base\"], \"clustering_evaluation.joblib\")\n",
    "    joblib.dump(eval_scores, eval_path)\n",
    "    logger.info(f\"Saved evaluation metrics to {eval_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in cluster evaluation: {str(e)}\")\n",
    "    logger.exception(\"Stack trace:\")\n",
    "\n",
    "logger.info(f\"Step 6 completed in {time.time() - step_start:.2f} seconds\")\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "# Pipeline Summary\n",
    "#---------------------------------------------------------------------------\n",
    "total_time = time.time() - start_time\n",
    "\n",
    "print_section_header(\"EEG PROCESSING PIPELINE COMPLETE\")\n",
    "logger.info(f\"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "logger.info(f\"Results saved to {output_dir}\")\n",
    "logger.info(\"\\nSummary:\")\n",
    "logger.info(f\"  - Bundles created/loaded: {bundle_info['total_bundles']}\")\n",
    "logger.info(f\"  - Number of clusters: {optimal_n}\")\n",
    "\n",
    "if eval_scores:\n",
    "    logger.info(\"  - Evaluation scores:\")\n",
    "    for metric, value in eval_scores.items():\n",
    "        logger.info(f\"    * {metric}: {value:.4f}\")\n",
    "\n",
    "logger.info(\"\\nOutput Files:\")\n",
    "logger.info(f\"  - Bundle info: {os.path.join(bundle_dir, 'bundle_info.joblib')}\")\n",
    "logger.info(f\"  - Metadata: {os.path.join(dirs['base'], 'metadata_with_clusters.csv')}\")\n",
    "logger.info(f\"  - Trained model: {os.path.join(dirs['models'], 'unsupervised_model.joblib')}\")\n",
    "logger.info(f\"  - Visualizations: {dirs['plots']}\")\n",
    "logger.info(f\"  - Log file: {log_file}\")\n",
    "\n",
    "logger.info(\"\\nNext steps:\")\n",
    "logger.info(\"  1. Review the cluster visualizations to understand the patterns\")\n",
    "logger.info(\"  2. Analyze clusters in relation to EEG channel characteristics\")\n",
    "logger.info(\"  3. Use clusters for supervised learning or further analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
