{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Real-time EEG Mental State Inference\n",
       "\n",
       "This notebook demonstrates how to use the EEG mental state inference system in real-time."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import time\n",
       "import ipywidgets as widgets\n",
       "from IPython.display import display, clear_output\n",
       "from datetime import datetime\n",
       "\n",
       "# Import our modules\n",
       "from common.mental_state_inference import (\n",
       "    generate_mental_state_mapping,\n",
       "    EEGRealTimePredictor,\n",
       "    real_time_eeg_demo\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Load Models and Generate Mental State Mapping"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Set up paths\n",
       "model_dir = './models/clustering'\n",
       "data_path = '../data'  # Change to your data directory\n",
       "\n",
       "# Generate mapping from clusters to mental states\n",
       "mental_state_mapping = generate_mental_state_mapping(\n",
       "    model_dir=model_dir,\n",
       "    data_sample_path=data_path,\n",
       "    method='feature_based'\n",
       ")\n",
       "\n",
       "print(f\"\\nMental state mapping: {mental_state_mapping}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Initialize Real-time Predictor"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Initialize real-time predictor\n",
       "predictor = EEGRealTimePredictor(\n",
       "    model_path=model_dir,\n",
       "    buffer_size=30,  # Number of samples to collect before prediction\n",
       "    step_size=5,     # Step size for sliding window\n",
       "    mental_state_mapping=mental_state_mapping\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Demo with Pre-recorded Data\n",
       "\n",
       "This demonstrates how the real-time prediction works using pre-recorded data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Run real-time demo with pre-recorded data\n",
       "results = real_time_eeg_demo(\n",
       "    predictor=predictor,\n",
       "    data_path=data_path,\n",
       "    duration_seconds=30,  # Run for 30 seconds\n",
       "    sample_interval=0.1   # 10Hz sampling rate\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Interactive Widget Demo\n",
       "\n",
       "This shows how you might integrate the predictor with interactive widgets."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Set up widgets\n",
       "output = widgets.Output()\n",
       "progress = widgets.FloatProgress(value=0, min=0, max=1, description='Buffer:')\n",
       "state_label = widgets.Label(value='Mental State: Waiting for data')\n",
       "confidence_label = widgets.Label(value='Confidence: -')\n",
       "start_button = widgets.Button(description='Start Demo')\n",
       "stop_button = widgets.Button(description='Stop')\n",
       "\n",
       "# Display the widgets\n",
       "display(widgets.HBox([start_button, stop_button]))\n",
       "display(progress, state_label, confidence_label)\n",
       "display(output)\n",
       "\n",
       "# Variables to control the demo\n",
       "demo_running = False\n",
       "\n",
       "# Function to run when Start button is clicked\n",
       "def on_start_button_clicked(b):\n",
       "    global demo_running\n",
       "    demo_running = True\n",
       "    \n",
       "    # Clear the predictor's buffer\n",
       "    predictor.clear_buffer()\n",
       "    \n",
       "    # Start the demo in a new thread\n",
       "    import threading\n",
       "    demo_thread = threading.Thread(target=run_interactive_demo)\n",
       "    demo_thread.daemon = True\n",
       "    demo_thread.start()\n",
       "\n",
       "# Function to run when Stop button is clicked\n",
       "def on_stop_button_clicked(b):\n",
       "    global demo_running\n",
       "    demo_running = False\n",
       "\n",
       "# Connect the button click events\n",
       "start_button.on_click(on_start_button_clicked)\n",
       "stop_button.on_click(on_stop_button_clicked)\n",
       "\n",
       "# Function to run the interactive demo\n",
       "def run_interactive_demo():\n",
       "    global demo_running\n",
       "    \n",
       "    # Load sample data\n",
       "    from common.helpers import load_eeg_data\n",
       "    if os.path.isdir(data_path):\n",
       "        file_dfs, _ = load_eeg_data(directory_path=data_path)\n",
       "        # Use first file\n",
       "        sample_df = list(file_dfs.values())[0]\n",
       "    else:\n",
       "        _, sample_df = load_eeg_data(single_file=data_path)\n",
       "    \n",
       "    # Process samples\n",
       "    sample_index = 0\n",
       "    while demo_running and sample_index < len(sample_df):\n",
       "        # Get sample\n",
       "        sample = sample_df.iloc[sample_index]\n",
       "        \n",
       "        # Add to predictor\n",
       "        buffer_full = predictor.add_sample(sample)\n",
       "        \n",
       "        # Update progress\n",
       "        progress.value = len(predictor.buffer) / predictor.buffer_size\n",
       "        \n",
       "        # Make prediction if buffer is full\n",
       "        if buffer_full:\n",
       "            prediction = predictor.predict()\n",
       "            \n",
       "            # Update widgets\n",
       "            if prediction['state']:\n",
       "                state_color = 'green' if prediction['state'] == 'focused' else 'blue'\n",
       "                state_label.value = f\"Mental State: <span style='color:{state_color}'>{prediction['state'].upper()}</span>\"\n",
       "            else:\n",
       "                state_label.value = \"Mental State: Waiting for data\"\n",
       "                \n",
       "            confidence_label.value = f\"Confidence: {prediction['confidence']:.2f}\"\n",
       "            \n",
       "            # Add to output\n",
       "            with output:\n",
       "                clear_output(wait=True)\n",
       "                print(f\"Time: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
       "                print(f\"State: {prediction['state']}\")\n",
       "                print(f\"Cluster: {prediction['cluster']}\")\n",
       "                print(f\"Confidence: {prediction['confidence']:.2f}\")\n",
       "                print(f\"Prediction time: {prediction.get('prediction_time', 0)*1000:.1f} ms\")\n",
       "                \n",
       "                # Plot the most recent prediction history\n",
       "                if len(predictor.recent_predictions) > 1:\n",
       "                    plt.figure(figsize=(8, 2))\n",
       "                    state_nums = [1 if s == 'focused' else 0 for s in predictor.recent_predictions]\n",
       "                    plt.plot(state_nums, 'o-')\n",
       "                    plt.yticks([0, 1], ['Relaxed', 'Focused'])\n",
       "                    plt.title('Recent Predictions')\n",
       "                    plt.tight_layout()\n",
       "                    plt.show()\n",
       "        \n",
       "        # Move to next sample\n",
       "        sample_index += 1\n",
       "        \n",
       "        # Sleep to simulate real-time\n",
       "        time.sleep(0.1)\n",
       "    \n",
       "    # Update status when done\n",
       "    if not demo_running:\n",
       "        with output:\n",
       "            print(\"Demo stopped by user\")\n",
       "    else:\n",
       "        with output:\n",
       "            print(\"Demo completed - reached end of data\")\n",
       "            \n",
       "    demo_running = False"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Manual Testing\n",
       "\n",
       "You can also manually test the predictor with your own data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Create a sample EEG datapoint\n",
       "# This would typically come from your EEG device\n",
       "# The structure should match your training data\n",
       "sample_data = {\n",
       "    'Delta': 0.5,\n",
       "    'Theta': 0.3,\n",
       "    'Alpha': 0.8,\n",
       "    'Beta': 0.2,\n",
       "    'Gamma': 0.1,\n",
       "    # Add other channels/features as needed\n",
       "}\n",
       "\n",
       "# Reset the predictor\n",
       "predictor.clear_buffer()\n",
       "\n",
       "# Add the sample\n",
       "predictor.add_sample(sample_data)\n",
       "\n",
       "# Check buffer status\n",
       "print(f\"Buffer fill level: {len(predictor.buffer)}/{predictor.buffer_size}\")\n",
       "\n",
       "# Note: You would need to add more samples to fill the buffer before making a prediction\n",
       "# In a real application, you would add samples as they come in from your EEG device"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Integration with Real EEG Device\n",
       "\n",
       "This is a template for how you might integrate with a real EEG device:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def integrate_with_eeg_device():\n",
       "    \"\"\"\n",
       "    Template function for integrating with a real EEG device\n",
       "    Replace the comments with actual device-specific code\n",
       "    \"\"\"\n",
       "    # Initialize the predictor\n",
       "    predictor = EEGRealTimePredictor(\n",
       "        model_path=model_dir,\n",
       "        buffer_size=30,\n",
       "        step_size=5,\n",
       "        mental_state_mapping=mental_state_mapping\n",
       "    )\n",
       "    \n",
       "    # Initialize your EEG device\n",
       "    # eeg_device = YourEEGDevice()\n",
       "    # eeg_device.connect()\n",
       "    \n",
       "    try:\n",
       "        # Main loop\n",
       "        while True:\n",
       "            # Get data from your EEG device\n",
       "            # raw_eeg_data = eeg_device.get_data()\n",
       "            \n",
       "            # Process the raw data into the format expected by the predictor\n",
       "            # processed_data = process_raw_eeg(raw_eeg_data)\n",
       "            \n",
       "            # Add to the predictor\n",
       "            # predictor.add_sample(processed_data)\n",
       "            \n",
       "            # Make prediction if buffer is full\n",
       "            # if len(predictor.buffer) >= predictor.buffer_size:\n",
       "            #     prediction = predictor.predict()\n",
       "            #     print(f\"Mental state: {prediction['state']}\")\n",
       "            \n",
       "            # Sleep to control sampling rate\n",
       "            time.sleep(0.1)  # 10Hz sampling rate\n",
       "            \n",
       "    except KeyboardInterrupt:\n",
       "        print(\"Stopping...\")\n",
       "    finally:\n",
       "        # Clean up\n",
       "        # eeg_device.disconnect()\n",
       "        pass\n",
       "\n",
       "# Uncomment to run with a real device\n",
       "# integrate_with_eeg_device()"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }